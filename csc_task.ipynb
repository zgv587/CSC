{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bb0c42b-3fa1-4b4c-934a-011db74e01ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/simple_csc/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "from data_processer import CSCDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11950720-5407-4506-b59e-deea88907b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    BertForSequenceClassification,\n",
    "    BertTokenizer,\n",
    "    get_scheduler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b29704ad-c868-49b1-af1e-845de0d659d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_err(raw_sentence, pred_sentence, corr_sentence):\n",
    "    matrices = [\"over_corr\", \"total_err\", \"true_corr\"]\n",
    "    char_level = {key: 0 for key in matrices}\n",
    "    sent_level = {key: 0 for key in matrices}\n",
    "\n",
    "    f1 = f2 = 0\n",
    "    for i, c in enumerate(raw_sentence):\n",
    "        pc, cc = pred_sentence[i], corr_sentence[i]\n",
    "\n",
    "        if cc != c:\n",
    "            char_level[\"total_err\"] += 1\n",
    "            char_level[\"true_corr\"] += pc == cc\n",
    "            f1 = 1\n",
    "        elif pc != cc:\n",
    "            char_level[\"over_corr\"] += 1\n",
    "            f2 = 1\n",
    "\n",
    "    if f1:\n",
    "        sent_level[\"true_corr\"] += all(pred_sentence == corr_sentence)\n",
    "        sent_level[\"total_err\"] += f1\n",
    "    sent_level[\"over_corr\"] += f2\n",
    "\n",
    "    return char_level, sent_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72747c97-3c76-4b65-8402-7d507c022b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, tokenizer, test_data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    matrices = [\"over_corr\", \"total_err\", \"true_corr\"]\n",
    "    test_char_level = {key: 0 for key in matrices}\n",
    "    test_sent_level = {key: 0 for key in matrices}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_data_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device).type(torch.float)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, src_mask=attention_mask)\n",
    "            logits = outputs.permute(0, 2, 1)\n",
    "\n",
    "            loss = cross_entropy(logits, labels, ignore_index=tokenizer.pad_token_id)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            t = torch.argmax(outputs, dim=-1)\n",
    "            nt = t * attention_mask\n",
    "            pred = tokenizer.batch_decode(nt, skip_special_tokens=True)\n",
    "\n",
    "            for i in range(len(t)):\n",
    "                char_level, sent_level = cal_err(input_ids[i], nt[i], labels[i])\n",
    "                test_char_level = {\n",
    "                    key: test_char_level[key] + v for key, v in char_level.items()\n",
    "                }\n",
    "                test_sent_level = {\n",
    "                    key: test_sent_level[key] + v for key, v in sent_level.items()\n",
    "                }\n",
    "        print(total_loss / len(test_data_loader), test_char_level, test_sent_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cddc97a-3f74-423b-b057-7cb0aa81c325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocessing sighan dataset: 2339it [00:00, 933886.44it/s]\n",
      "preprocessing sighan dataset: 100%|██████████| 2339/2339 [00:00<00:00, 1522184.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共2339句，共73264字，最长的句子有171字\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocessing sighan dataset: 3437it [00:00, 890855.45it/s]\n",
      "preprocessing sighan dataset: 100%|██████████| 3437/3437 [00:00<00:00, 1409309.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共3437句，共170330字，最长的句子有258字\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/simple_csc/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch:1/10: 100%|██████████| 147/147 [00:09<00:00, 14.76it/s, loss=2.235]\n",
      "/root/anaconda3/envs/simple_csc/lib/python3.10/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 知 到 你 會 難 過 ， 要 是 我 啊 ， 我 也 會 傷 心 難 過 啊 ， 可 是 你 也 要 想 要 是 你 是 他 ， 你 會 怎 樣 。\n",
      "我 知 到 你 會 難 過 ， 要 是 我 灣 ， 我 也 會 。 心 難 過 來 ， 可 是 你 也 要 想 要 是 你 是 他 ， 你 會 怎 樣 。\n",
      "我 知 道 你 會 難 過 ， 要 是 我 啊 ， 我 也 會 傷 心 難 過 啊 ， 可 是 你 也 要 想 要 是 你 是 他 ， 你 會 怎 樣 。\n",
      "({'over_corr': 3, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "坐 在 沙 發 ， 喝 酒 和 看 般 球 給 我 很 高 興 。\n",
      "要 在 的 發 ， ， 的 和 看 的 給 我 很 高 興 。\n",
      "坐 在 沙 發 ， 喝 酒 和 看 棒 球 給 我 很 高 興 。\n",
      "({'over_corr': 5, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "那 筆 錢 可 以 來 用 在 教 義 方 面 。 增 加 老 師 薪 水 、 或 著 投 資 在 語 言 、 運 動 、 數 學 具 方 面 。\n",
      "那 一 錢 可 以 來 用 在 教 他 方 面 。 會 加 老 師 長 孩 、 或 著 ， 都 在 是 台 、 多 動 、 。 學 很 方 面 。\n",
      "那 筆 錢 可 以 來 用 在 教 育 方 面 。 增 加 老 師 薪 水 、 或 者 投 資 在 語 言 、 運 動 、 數 學 幾 方 面 。\n",
      "({'over_corr': 10, 'total_err': 3, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 1 Loss: 4.6068473243389\n",
      "nan {'over_corr': 40198, 'total_err': 5278, 'true_corr': tensor(11, device='cuda:0')} {'over_corr': 3428, 'total_err': 3436, 'true_corr': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:2/10: 100%|██████████| 147/147 [00:09<00:00, 15.93it/s, loss=1.147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "來 我 們 看 這 節 目 很 不 做 ， 我 很 喜 歡 。\n",
      "來 我 們 看 這 的 目 很 不 做 ， 我 很 喜 歡 。\n",
      "來 我 們 看 這 節 目 很 不 錯 ， 我 很 喜 歡 。\n",
      "({'over_corr': 1, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "請 不 要 太 難 過 你 朋 有 這 麼 有 反 應 也 是 理 所 當 然 的 嘛 。\n",
      "請 不 要 太 難 過 你 朋 有 這 麼 有 反 應 也 是 理 所 當 然 的 的 。\n",
      "請 不 要 太 難 過 你 朋 友 這 麼 有 反 應 也 是 理 所 當 然 的 嘛 。\n",
      "({'over_corr': 1, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "電 影 叫 「 － 」 ， 我 覺 得 是 很 客 愛 的 電 影 。\n",
      "電 影 叫 「 最 的 不 」 ， 我 覺 得 是 很 愛 的 電 影 。\n",
      "電 影 叫 「 － 」 ， 我 覺 得 是 很 可 愛 的 電 影 。\n",
      "({'over_corr': 3, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 2 Loss: 1.4612771191564546\n",
      "nan {'over_corr': 17765, 'total_err': 5278, 'true_corr': tensor(185, device='cuda:0')} {'over_corr': 3144, 'total_err': 3436, 'true_corr': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:3/10: 100%|██████████| 147/147 [00:09<00:00, 15.94it/s, loss=0.852]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可 是 這 個 巴 士 來 得 時 很 慢 ， 結 果 我 來 不 起 上 課 。\n",
      "可 是 這 個 們 士 來 得 時 很 慢 ， 結 果 我 來 不 起 上 課 。\n",
      "可 是 這 個 巴 士 來 得 時 很 慢 ， 結 果 我 來 不 及 上 課 。\n",
      "({'over_corr': 1, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "由 於 近 幾 周 工 廠 之 「 噪 音 」 及 「 臭 味 」 極 多 的 狀 況 ， 令 附 近 的 住 宅 戶 感 到 不 適 ， 因 此 本 人 藉 由 這 封 信 希 望 廠 長 能 夠 立 刻 出 場 處 理 。\n",
      "由 於 近 幾 週 工 廠 之 「 噪 音 」 及 「 臭 味 」 極 多 的 狀 況 ， 一 附 近 的 住 來 都 感 到 不 適 ， 因 此 本 人 況 由 這 封 信 希 望 廠 長 能 夠 立 刻 出 場 處 理 。\n",
      "由 於 近 幾 週 工 廠 之 「 噪 音 」 及 「 臭 味 」 極 多 的 狀 況 ， 令 附 近 的 住 宅 戶 感 到 不 適 ， 因 此 本 人 藉 由 這 封 信 希 望 廠 長 能 夠 立 刻 出 廠 處 理 。\n",
      "({'over_corr': 4, 'total_err': 2, 'true_corr': tensor(1, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "那 寵 物 出 租 公 司 的 最 優 點 是 出 租 以 前 有 面 試 並 訓 練 課 程 ， 這 很 有 信 用 得 事 。\n",
      "那 寵 物 出 租 公 司 的 最 優 點 是 出 租 以 前 有 面 試 並 訓 練 課 程 ， 這 很 有 信 用 得 事 。\n",
      "那 寵 物 出 租 公 司 的 最 優 點 是 出 租 以 前 有 面 試 並 訓 練 課 程 ， 這 很 有 信 用 的 事 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 3 Loss: 0.8979728842268184\n",
      "nan {'over_corr': 12182, 'total_err': 5278, 'true_corr': tensor(235, device='cuda:0')} {'over_corr': 2844, 'total_err': 3436, 'true_corr': 17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:4/10: 100%|██████████| 147/147 [00:09<00:00, 15.93it/s, loss=0.418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "電 影 叫 「 － 」 ， 我 覺 得 是 很 客 愛 的 電 影 。\n",
      "電 影 叫 「 有 」 ， 我 覺 得 是 很 客 愛 的 電 影 。\n",
      "電 影 叫 「 － 」 ， 我 覺 得 是 很 可 愛 的 電 影 。\n",
      "({'over_corr': 1, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "我 剛 才 受 到 你 的 信 。 根 據 你 的 信 我 知 道 你 在 遇 見 很 大 的 事 情 。\n",
      "我 剛 才 受 到 你 的 信 。 跟 據 你 的 信 我 知 道 你 在 遇 見 很 大 的 事 情 。\n",
      "我 剛 才 收 到 你 的 信 。 根 據 你 的 信 我 知 道 你 在 遇 見 很 大 的 事 情 。\n",
      "({'over_corr': 1, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "他 門 馬 上 打 包 都 東 西 ， 下 雨 更 大 ， 所 以 他 們 搬 到 別 的 地 方 。\n",
      "他 們 馬 上 打 包 都 東 西 ， 下 雨 更 大 ， 所 以 他 們 搬 到 別 的 地 方 。\n",
      "他 們 馬 上 打 包 都 東 西 ， 下 雨 更 大 ， 所 以 他 們 搬 到 別 的 地 方 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(1, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 1})\n",
      "Epoch 4 Loss: 0.6684324765691951\n",
      "nan {'over_corr': 9337, 'total_err': 5278, 'true_corr': tensor(240, device='cuda:0')} {'over_corr': 2544, 'total_err': 3436, 'true_corr': 22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:5/10: 100%|██████████| 147/147 [00:09<00:00, 15.93it/s, loss=0.519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "他 們 覺 得 竟 然 不 是 你 拿 的 ， 你 就 不 介 意 給 人 家 檢 察 背 包 。\n",
      "他 們 覺 得 竟 然 不 是 你 拿 的 ， 你 就 不 建 意 給 人 家 檢 察 背 包 。\n",
      "他 們 覺 得 竟 然 不 是 你 拿 的 ， 你 就 不 介 意 給 人 家 檢 查 背 包 。\n",
      "({'over_corr': 1, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "還 有 在 那 個 包 包 裡 面 裡 可 以 放 很 多 禮 物 待 你 的 國 家 ， 所 以 你 可 以 那 些 禮 物 給 你 的 家 人 讓 他 們 高 心 。\n",
      "還 有 在 那 個 包 包 裡 面 裡 可 以 放 很 多 禮 物 待 你 的 國 家 ， 所 以 你 可 以 那 些 禮 物 給 你 的 家 人 讓 他 們 高 心 。\n",
      "還 有 在 那 個 包 包 裡 面 裡 可 以 放 很 多 禮 物 到 你 的 國 家 ， 所 以 你 可 以 那 些 禮 物 給 你 的 家 人 讓 他 們 高 興 。\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "我 的 未 來 的 工 作 不 會 因 影 樂 我 的 教 訓 對 我 的 父 母 親 與 我 的 家 人 。\n",
      "我 的 未 來 的 工 作 不 會 因 影 樂 我 的 教 訓 對 我 的 父 母 親 與 我 的 家 人 。\n",
      "我 的 未 來 的 工 作 不 會 陰 影 了 我 的 教 訓 對 我 的 父 母 親 與 我 的 家 人 。\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 5 Loss: 0.5484020752566201\n",
      "nan {'over_corr': 7551, 'total_err': 5278, 'true_corr': tensor(249, device='cuda:0')} {'over_corr': 2323, 'total_err': 3436, 'true_corr': 30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:6/10: 100%|██████████| 147/147 [00:09<00:00, 15.91it/s, loss=0.480]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "但 是 有 很 多 課 程 不 因 該 在 電 腦 上 教 ， 例 如 語 言 、 閱 讀 、 寫 作 等 。\n",
      "但 是 有 很 多 課 程 不 因 該 在 電 腦 上 教 ， 例 如 語 言 、 閱 讀 、 寫 作 等 。\n",
      "但 是 有 很 多 課 程 不 應 該 在 電 腦 上 教 ， 例 如 語 言 、 閱 讀 、 寫 作 等 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "以 前 都 很 希 望 可 以 每 個 學 期 修 一 兩 門 課 而 已 ， 這 樣 我 研 究 的 科 目 能 夠 薰 陶 我 的 心 力 讓 我 好 好 笑 話 拿 份 專 業 知 識 ， 也 能 同 時 由 精 神 管 理 工 作 和 家 庭 的 事 情 。\n",
      "以 前 都 很 希 望 可 以 每 個 學 期 修 一 兩 們 課 而 已 ， 這 樣 我 研 究 的 科 目 能 夠 原 應 我 的 心 力 讓 我 好 好 笑 話 拿 份 專 業 知 識 ， 也 能 同 時 由 精 神 管 理 工 作 和 家 庭 的 事 情 。\n",
      "以 前 都 很 希 望 可 以 每 個 學 期 修 一 兩 門 課 而 已 ， 這 樣 我 研 究 的 科 目 能 夠 薰 陶 我 的 心 力 讓 我 好 好 消 耗 拿 份 專 業 知 識 ， 也 能 同 時 有 精 神 管 理 工 作 和 家 庭 的 事 情 。\n",
      "({'over_corr': 3, 'total_err': 3, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "小 時 候 常 常 可 以 從 早 上 ， 不 吃 不 喝 的 一 直 坐 在 電 腦 前 面 到 晚 上 。\n",
      "小 時 候 常 常 可 以 從 早 上 ， 不 吃 不 喝 的 一 直 坐 在 電 腦 前 面 到 晚 上 。\n",
      "小 時 候 常 常 可 以 從 早 上 ， 不 吃 不 喝 地 一 直 坐 在 電 腦 前 面 到 晚 上 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 6 Loss: 0.4712370360384182\n",
      "nan {'over_corr': 6661, 'total_err': 5278, 'true_corr': tensor(294, device='cuda:0')} {'over_corr': 2197, 'total_err': 3436, 'true_corr': 40}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:7/10: 100%|██████████| 147/147 [00:09<00:00, 15.90it/s, loss=0.232]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有 一 個 開 紅 色 車 的 男 人 ， 他 看 見 我 在 路 邊 交 馬 上 停 車 。\n",
      "有 一 個 開 紅 色 車 的 男 人 ， 他 看 見 我 在 路 邊 交 馬 上 停 車 。\n",
      "有 一 個 開 紅 色 車 的 男 人 ， 他 看 見 我 在 路 邊 叫 馬 上 停 車 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "你 找 到 你 最 喜 歡 的 工 作 ， 我 也 很 高 心 。\n",
      "你 找 到 你 最 喜 歡 的 工 作 ， 我 也 很 高 心 。\n",
      "你 找 到 你 最 喜 歡 的 工 作 ， 我 也 很 高 興 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "我 想 網 站 也 是 一 個 東 西 很 好 的 ， 什 麼 不 董 的 話 都 可 以 上 網 看 就 知 道 啊 ， 所 以 網 路 隊 我 來 講 是 很 好 的 ， 可 是 隊 小 孩 子 的 有 一 點 不 好 。\n",
      "我 想 網 站 也 是 一 個 東 西 很 好 的 ， 什 麼 不 懂 的 話 都 可 以 上 網 看 就 知 道 啊 ， 所 以 網 路 對 我 來 講 是 很 好 的 ， 可 是 對 小 孩 子 的 有 一 點 不 好 。\n",
      "我 想 網 站 也 是 一 個 東 西 很 好 的 ， 什 麼 不 懂 的 話 都 可 以 上 網 看 就 知 道 啊 ， 所 以 網 路 對 我 來 講 是 很 好 的 ， 可 是 對 小 孩 子 的 有 一 點 不 好 。\n",
      "({'over_corr': 0, 'total_err': 3, 'true_corr': tensor(3, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 1})\n",
      "Epoch 7 Loss: 0.4110492467880249\n",
      "nan {'over_corr': 6514, 'total_err': 5278, 'true_corr': tensor(301, device='cuda:0')} {'over_corr': 2186, 'total_err': 3436, 'true_corr': 47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:8/10: 100%|██████████| 147/147 [00:09<00:00, 15.98it/s, loss=0.347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "希 望 你 們 那 個 很 特 別 的 一 天 過 的 很 開 心 ！\n",
      "希 望 你 們 那 個 很 特 別 的 一 天 過 的 很 開 心 ！\n",
      "希 望 你 們 那 個 很 特 別 的 一 天 過 得 很 開 心 ！\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "他 等 一 下 ， 戶 然 他 看 到 一 輛 汽 車 。\n",
      "他 等 一 下 ， 戶 然 他 看 到 一 輛 汽 車 。\n",
      "他 等 一 下 ， 忽 然 他 看 到 一 輛 汽 車 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "起 點 五 十 分 公 車 來 了 ， 可 是 公 車 裡 很 多 人 ， 好 像 進 不 去 。\n",
      "起 點 五 十 分 公 車 來 了 ， 可 是 公 車 裡 很 多 人 ， 好 像 進 不 去 。\n",
      "七 點 五 十 分 公 車 來 了 ， 可 是 公 車 裡 很 多 人 ， 好 像 進 不 去 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 8 Loss: 0.37050490942942044\n",
      "nan {'over_corr': 5628, 'total_err': 5278, 'true_corr': tensor(341, device='cuda:0')} {'over_corr': 2014, 'total_err': 3436, 'true_corr': 66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:9/10: 100%|██████████| 147/147 [00:09<00:00, 15.94it/s, loss=0.231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "請 想 像 一 位 未 來 總 統 候 選 人 ； 如 果 媒 體 捉 去 她 小 時 候 影 片 ， 發 現 甚 麼 缺 點 ， 就 算 是 小 時 候 ， 選 民 必 然 會 受 不 好 的 影 像 。\n",
      "請 想 像 一 位 未 來 總 統 候 選 人 ； 如 果 媒 體 好 去 她 小 時 候 影 片 ， 發 現 甚 麼 缺 點 ， 就 算 是 小 時 候 ， 選 民 必 然 會 受 不 好 的 影 像 。\n",
      "請 想 像 一 位 未 來 總 統 候 選 人 ； 如 果 媒 體 捉 去 她 小 時 候 影 片 ， 發 現 甚 麼 缺 點 ， 就 算 是 小 時 候 ， 選 民 必 然 會 受 不 好 的 影 響 。\n",
      "({'over_corr': 1, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "裝 錄 音 機 在 每 個 教 室 裡 有 很 多 的 好 處 ， 對 我 來 說 莊 錄 影 機 在 教 室 裡 的 好 處 比 壞 處 多 了 。\n",
      "裝 錄 音 機 在 每 個 教 室 裡 有 很 多 的 好 處 ， 對 我 來 說 裝 錄 影 機 在 教 室 裡 的 好 處 比 壞 處 多 了 。\n",
      "裝 錄 影 機 在 每 個 教 室 裡 有 很 多 的 好 處 ， 對 我 來 說 裝 錄 影 機 在 教 室 裡 的 好 處 比 壞 處 多 了 。\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(1, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "圖 書 館 沒 有 門 票 也 不 用 附 那 邊 的 電 費 ， 有 那 麼 多 空 的 話 就 去 那 邊 看 書 可 以 得 到 很 多 很 多 知 識 。\n",
      "圖 書 館 沒 有 們 漂 也 不 用 附 那 邊 的 電 費 ， 有 那 麼 多 空 的 話 就 去 那 邊 看 書 可 以 得 到 很 多 很 多 知 識 。\n",
      "圖 書 館 沒 有 門 票 也 不 用 付 那 邊 的 電 費 ， 有 那 麼 多 空 的 話 就 去 那 邊 看 書 可 以 得 到 很 多 很 多 知 識 。\n",
      "({'over_corr': 2, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 9 Loss: 0.3364502977149016\n",
      "nan {'over_corr': 5436, 'total_err': 5278, 'true_corr': tensor(309, device='cuda:0')} {'over_corr': 1979, 'total_err': 3436, 'true_corr': 61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:10/10: 100%|██████████| 147/147 [00:09<00:00, 15.95it/s, loss=0.243]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一 方 面 可 以 不 斷 的 訓 練 自 己 的 人 生 知 識 ， 也 可 以 證 明 自 己 ， 提 高 女 人 在 社 會 的 地 位 。\n",
      "一 方 面 可 以 不 斷 的 訓 練 自 己 的 人 生 知 識 ， 也 可 以 證 明 自 己 ， 提 高 女 人 在 社 會 的 地 位 。\n",
      "一 方 面 可 以 不 斷 地 訓 練 自 己 的 人 生 知 識 ， 也 可 以 證 明 自 己 ， 提 高 女 人 在 社 會 的 地 位 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "聽 說 你 生 病 了 ， 也 不 看 到 你 上 個 。\n",
      "聽 說 你 生 病 了 ， 也 不 看 到 你 上 個 。\n",
      "聽 說 你 生 病 了 ， 也 不 看 到 你 上 課 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "還 有 隨 便 丟 掉 的 懷 人 抓 他 。 被 他 罰 很 多 錢 才 對 的 。\n",
      "還 有 隨 便 丟 掉 的 懷 人 抓 他 。 被 他 罰 很 多 錢 才 對 的 。\n",
      "還 有 隨 便 丟 掉 的 壞 人 抓 他 。 被 他 罰 很 多 錢 才 對 的 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 10 Loss: 0.30734801474882634\n",
      "nan {'over_corr': 5085, 'total_err': 5278, 'true_corr': tensor(349, device='cuda:0')} {'over_corr': 1896, 'total_err': 3436, 'true_corr': 70}\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "from models import Seq2SeqModel\n",
    "from torch.nn.functional import cross_entropy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# temp_data\n",
    "nhead = 4  # 多头注意力机制的头数\n",
    "num_decoder_layers = 2\n",
    "dim_feedforward = 3072\n",
    "max_seq_len = 128\n",
    "dropout = 0.1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tokenizer = BertTokenizer.from_pretrained(checkpoint)\n",
    "    bert = BertModel.from_pretrained(checkpoint)\n",
    "\n",
    "    train_dataset = CSCDataset([SIGHAN_train_dir_err, SIGHAN_train_dir_corr], tokenizer)\n",
    "    train_data_loader = DataLoader(\n",
    "        train_dataset, num_workers=0, shuffle=True, batch_size=16\n",
    "    )\n",
    "\n",
    "    test_dataset = CSCDataset(\n",
    "        [SIGHAN_train_dir_err14, SIGHAN_train_dir_corr14], tokenizer\n",
    "    )\n",
    "    test_data_loader = DataLoader(\n",
    "        test_dataset, num_workers=0, shuffle=True, batch_size=32\n",
    "    )\n",
    "\n",
    "    model = Seq2SeqModel(\n",
    "        bert, nhead, num_decoder_layers, dim_feedforward, max_seq_len, dropout\n",
    "    )\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(\n",
    "            enumerate(train_data_loader),\n",
    "            desc=f\"Epoch:{epoch+1}/{epochs}\",\n",
    "            total=len(train_data_loader),\n",
    "        )\n",
    "\n",
    "        for i, batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device).type(torch.float)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, src_mask=attention_mask)\n",
    "            logits = outputs.permute(0, 2, 1)  # (batch_size, vocab_size, seq_len)\n",
    "\n",
    "            # 反向传播在这，故labels不需要传入模型\n",
    "            loss = cross_entropy(logits, labels, ignore_index=tokenizer.pad_token_id)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            progress_bar.set_postfix({\"loss\": \"{:.3f}\".format(loss.item())})\n",
    "\n",
    "        t = torch.argmax(outputs, dim=-1)\n",
    "        nt = t * attention_mask\n",
    "        pred = tokenizer.batch_decode(nt, skip_special_tokens=True)\n",
    "        # print(pred)\n",
    "        # print(f\"origin{tokenizer.batch_decode(labels, skip_special_tokens=True)}\")\n",
    "\n",
    "        for i, v in enumerate(nt):\n",
    "            r, l = input_ids[i], labels[i]\n",
    "            print(tokenizer.decode(r, skip_special_tokens=True))\n",
    "            print(tokenizer.decode(v, skip_special_tokens=True))\n",
    "            print(tokenizer.decode(l, skip_special_tokens=True))\n",
    "            print(cal_err(r, v, l))\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss / len(train_data_loader)}\")\n",
    "        test(model, tokenizer, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f485237-bafa-452c-b127-2a2daeb44b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1/10: 100%|██████████| 147/147 [00:09<00:00, 15.90it/s, loss=0.169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "上 課 時 間 十 七 點 四 十 分 ， 八 點 我 才 上 車 去 我 遲 到 了 ， 怎 麼 辦 ？\n",
      "上 課 時 間 十 七 點 四 十 分 ， 八 點 我 才 上 車 去 我 遲 到 了 ， 怎 麼 辦 ？\n",
      "上 課 時 間 是 七 點 四 十 分 ， 八 點 我 才 上 車 去 我 遲 到 了 ， 怎 麼 辦 ？\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "謝 謝 看 我 的 意 見 ， 而 且 請 你 考 慮 我 的 意 見 以 下 。\n",
      "謝 謝 看 我 的 意 見 ， 而 且 請 你 考 慮 我 的 意 見 以 下 。\n",
      "謝 謝 看 我 的 意 見 ， 而 且 請 你 考 慮 我 的 意 見 一 下 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "由 於 昨 天 家 裡 比 較 熱 ， 所 以 我 們 打 開 窗 戶 ， 怎 麼 可 能 予 想 ， 外 面 臭 得 要 命 。\n",
      "由 於 昨 天 家 裡 比 較 熱 ， 所 以 我 們 打 開 窗 戶 ， 怎 麼 可 能 予 想 ， 外 面 臭 得 要 命 。\n",
      "由 於 昨 天 家 裡 比 較 熱 ， 所 以 我 們 打 開 窗 戶 ， 怎 麼 可 能 預 想 ， 外 面 臭 得 要 命 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 1 Loss: 0.2833105677447351\n",
      "nan {'over_corr': 5342, 'total_err': 5278, 'true_corr': tensor(425, device='cuda:0')} {'over_corr': 1977, 'total_err': 3436, 'true_corr': 86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:2/10: 100%|██████████| 147/147 [00:09<00:00, 15.88it/s, loss=0.240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "對 這 些 人 要 看 綠 色 至 少 １５ 分 鐘 、 綠 色 會 給 人 的 研 舒 服 的 感 覺 、 但 是 沒 有 真 正 綠 色 的 環 境 、 那 我 們 又 要 開 始 研 究 為 了 綠 色 的 綠 色 、 那 也 要 花 錢 。\n",
      "對 這 些 人 要 看 綠 色 至 少 １５ 分 鐘 、 綠 色 會 給 人 的 研 舒 服 的 感 覺 、 但 是 沒 有 真 正 綠 色 的 環 境 、 那 我 們 又 要 開 始 研 究 為 了 綠 色 的 綠 色 、 那 也 要 花 錢 。\n",
      "對 這 些 人 要 看 綠 色 至 少 １５ 分 鐘 、 綠 色 會 給 人 的 顏 舒 服 的 感 覺 、 但 是 沒 有 真 正 綠 色 的 環 境 、 那 我 們 又 要 開 始 研 究 為 了 綠 色 的 綠 色 、 那 也 要 花 錢 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "我 們 也 有 證 明 的 質 料 給 您 思 考 ， 也 得 看 您 願 不 願 意 跟 我 們 座 談 。\n",
      "我 們 也 有 證 明 的 質 料 給 您 思 考 ， 也 得 看 您 願 不 願 意 跟 我 們 坐 談 。\n",
      "我 們 也 有 證 明 的 資 料 給 您 思 考 ， 也 得 看 您 願 不 願 意 跟 我 們 座 談 。\n",
      "({'over_corr': 1, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "從 沒 有 噪 音 和 臭 味 ， 為 何 你 們 的 工 廠 最 近 會 造 出 那 麼 強 列 噪 音 與 臭 味 呢 ？\n",
      "從 沒 有 噪 音 和 臭 味 ， 為 何 你 們 的 工 廠 最 近 會 造 出 那 麼 強 列 噪 音 與 臭 味 呢 ？\n",
      "從 沒 有 噪 音 和 臭 味 ， 為 何 你 們 的 工 廠 最 近 會 造 出 那 麼 強 烈 噪 音 與 臭 味 呢 ？\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 2 Loss: 0.26251709481485846\n",
      "nan {'over_corr': 5770, 'total_err': 5278, 'true_corr': tensor(432, device='cuda:0')} {'over_corr': 2118, 'total_err': 3436, 'true_corr': 73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:3/10: 100%|██████████| 147/147 [00:09<00:00, 15.85it/s, loss=0.238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "他 們 不 高 興 因 為 他 們 的 衣 服 溪 溪 的 。\n",
      "他 們 不 高 興 因 為 他 們 的 衣 服 濕 濕 的 。\n",
      "他 們 不 高 興 因 為 他 們 的 衣 服 濕 濕 的 。\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(2, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 1})\n",
      "薪 水 少 很 多 和 工 作 天 也 變 少 ， 用 另 外 角 度 來 想 ， 當 作 給 自 已 的 休 息 時 間 。\n",
      "薪 水 少 很 多 和 工 作 天 也 變 少 ， 用 另 外 角 度 來 想 ， 當 作 給 自 已 的 休 息 時 間 。\n",
      "薪 水 少 很 多 和 工 作 天 也 變 少 ， 用 另 外 角 度 來 想 ， 當 作 給 自 己 的 休 息 時 間 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "現 階 段 的 這 個 非 常 時 期 我 們 也 只 好 咬 緊 牙 關 ， 努 力 渡 過 難 關 。\n",
      "現 階 段 的 這 個 非 常 時 期 我 們 也 只 好 有 緊 牙 關 ， 努 力 度 過 難 關 。\n",
      "現 階 段 的 這 個 非 常 時 期 我 們 也 只 好 咬 緊 牙 關 ， 努 力 度 過 難 關 。\n",
      "({'over_corr': 1, 'total_err': 1, 'true_corr': tensor(1, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 3 Loss: 0.2443779676544423\n",
      "nan {'over_corr': 6284, 'total_err': 5278, 'true_corr': tensor(484, device='cuda:0')} {'over_corr': 2268, 'total_err': 3436, 'true_corr': 91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:4/10: 100%|██████████| 147/147 [00:09<00:00, 15.88it/s, loss=0.260]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "張 愛 文 和 林 美 美 不 能 一 起 去 那 理 。\n",
      "張 愛 文 和 林 美 美 不 能 一 起 去 那 理 。\n",
      "張 愛 文 和 林 美 美 不 能 一 起 去 那 裡 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "上 課 一 後 ， 我 真 的 很 高 興 因 為 我 的 老 師 是 一 前 的 那 個 小 姐 。\n",
      "上 課 一 後 ， 我 真 的 很 高 興 因 為 我 的 老 師 是 一 前 的 那 個 小 姐 。\n",
      "上 課 以 後 ， 我 真 的 很 高 興 因 為 我 的 老 師 是 以 前 的 那 個 小 姐 。\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "第 一 個 是 跟 生 音 有 問 題 、 第 二 個 是 跟 味 道 有 問 題 。\n",
      "第 一 個 是 跟 生 音 有 問 題 、 第 二 個 是 跟 味 道 有 問 題 。\n",
      "第 一 個 是 跟 聲 音 有 問 題 、 第 二 個 是 跟 味 道 有 問 題 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 4 Loss: 0.22705515742707413\n",
      "nan {'over_corr': 8015, 'total_err': 5278, 'true_corr': tensor(556, device='cuda:0')} {'over_corr': 2530, 'total_err': 3436, 'true_corr': 74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:5/10: 100%|██████████| 147/147 [00:09<00:00, 15.96it/s, loss=0.221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "因 為 現 在 ， 我 們 再 得 這 一 時 代 ， 就 是 不 能 相 信 別 人 家 的 很 冷 淡 的 時 代 嘛 ！\n",
      "因 為 現 在 ， 我 們 再 得 這 一 時 代 ， 就 是 不 能 相 信 別 人 家 的 很 冷 淡 的 時 代 嘛 ！\n",
      "因 為 現 在 ， 我 們 在 的 這 一 時 代 ， 就 是 不 能 相 信 別 人 家 的 很 冷 淡 的 時 代 嘛 ！\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "他 的 班 有 一 位 王 大 明 喜 歡 的 人 ， 可 是 她 還 不 知 道 ： 這 是 王 大 明 的 米 米 ！\n",
      "他 的 班 有 一 位 王 大 明 喜 歡 的 人 ， 可 是 她 還 不 知 道 ： 這 是 王 大 明 的 迷 迷 ！\n",
      "他 的 班 有 一 位 王 大 明 喜 歡 的 人 ， 可 是 她 還 不 知 道 ： 這 是 王 大 明 的 秘 密 ！\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "他 從 是 坐 公 車 去 學 校 。\n",
      "他 從 是 坐 公 車 去 學 校 。\n",
      "他 總 是 坐 公 車 去 學 校 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 5 Loss: 0.2109994773759323\n",
      "nan {'over_corr': 10946, 'total_err': 5278, 'true_corr': tensor(639, device='cuda:0')} {'over_corr': 2884, 'total_err': 3436, 'true_corr': 70}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:6/10: 100%|██████████| 147/147 [00:09<00:00, 15.95it/s, loss=0.157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "到 新 科 技 的 時 代 ， 電 腦 對 我 們 人 類 實 在 有 很 大 的 貢 獻 。 而 且 在 加 上 網 路 的 功 能 ， 把 電 腦 的 運 作 變 成 更 完 美 。\n",
      "到 新 科 技 的 時 代 ， 電 腦 對 我 們 人 類 實 在 有 很 大 的 貢 獻 。 而 且 在 加 上 網 路 的 功 能 ， 把 電 腦 的 運 作 變 成 更 完 美 。\n",
      "到 新 科 技 的 時 代 ， 電 腦 對 我 們 人 類 實 在 有 很 大 的 貢 獻 。 而 且 再 加 上 網 路 的 功 能 ， 把 電 腦 的 運 作 變 成 更 完 美 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "大 多 的 現 代 人 慎 怕 小 朋 友 會 出 什 麼 問 題 ， 而 緊 迫 釘 人 。\n",
      "大 多 的 現 代 人 深 怕 小 朋 友 會 出 什 麼 問 題 ， 而 緊 迫 盯 人 。\n",
      "大 多 的 現 代 人 深 怕 小 朋 友 會 出 什 麼 問 題 ， 而 緊 迫 盯 人 。\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(2, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 1})\n",
      "從 我 得 學 校 圖 書 館 時 數 紀 錄 卡 裡 面 來 看 ， 每 個 同 學 在 網 路 室 的 時 數 高 於 閱 讀 室 三 倍 。\n",
      "從 我 得 學 校 圖 書 館 時 數 紀 錄 卡 裡 面 來 看 ， 每 個 同 學 在 網 路 室 的 時 數 高 於 閱 讀 室 三 倍 。\n",
      "從 我 的 學 校 圖 書 館 時 數 紀 錄 卡 裡 面 來 看 ， 每 個 同 學 在 網 路 室 的 時 數 高 於 閱 讀 室 三 倍 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 6 Loss: 0.19457765486167403\n",
      "nan {'over_corr': 15331, 'total_err': 5278, 'true_corr': tensor(606, device='cuda:0')} {'over_corr': 3099, 'total_err': 3436, 'true_corr': 46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:7/10: 100%|██████████| 147/147 [00:09<00:00, 15.94it/s, loss=0.093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可 是 在 學 校 的 時 候 ， 老 師 會 公 平 的 對 待 每 個 小 學 生 ， 如 果 錯 就 要 罰 ， 怪 的 就 會 獎 。\n",
      "可 是 在 學 校 的 時 候 ， 老 師 會 公 平 的 對 待 每 個 小 學 生 ， 如 果 錯 就 要 罰 ， 怪 的 就 會 獎 。\n",
      "可 是 在 學 校 的 時 候 ， 老 師 會 公 平 的 對 待 每 個 小 學 生 ， 如 果 錯 就 要 罰 ， 乖 的 就 會 獎 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "可 是 他 們 ， 尤 其 是 從 來 沒 有 養 過 的 人 再 開 始 養 之 前 ， 只 會 想 像 養 了 以 後 有 什 麼 好 的 事 情 ， 卻 不 考 慮 訓 練 、 照 顧 還 有 散 步 等 等 的 辛 苦 。\n",
      "可 是 他 們 ， 尤 其 是 從 來 沒 有 養 過 的 人 再 開 始 養 之 前 ， 只 會 想 像 養 了 以 後 有 什 麼 好 的 事 情 ， 卻 不 考 慮 訓 練 、 照 顧 還 有 散 步 等 等 的 辛 苦 。\n",
      "可 是 他 們 ， 尤 其 是 從 來 沒 有 養 過 的 人 在 開 始 養 之 前 ， 只 會 想 像 養 了 以 後 有 什 麼 好 的 事 情 ， 卻 不 考 慮 訓 練 、 照 顧 還 有 散 步 等 等 的 辛 苦 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "我 覺 得 你 應 該 也 吃 藥 也 休 息 機 天 就 好 了 。\n",
      "我 覺 得 你 應 該 也 吃 藥 也 休 息 機 天 就 好 了 。\n",
      "我 覺 得 你 應 該 也 吃 藥 也 休 息 幾 天 就 好 了 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 7 Loss: 0.1789718660063484\n",
      "nan {'over_corr': 14539, 'total_err': 5278, 'true_corr': tensor(510, device='cuda:0')} {'over_corr': 3050, 'total_err': 3436, 'true_corr': 37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:8/10: 100%|██████████| 147/147 [00:09<00:00, 15.96it/s, loss=0.128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "因 為 現 在 ， 我 們 再 得 這 一 時 代 ， 就 是 不 能 相 信 別 人 家 的 很 冷 淡 的 時 代 嘛 ！\n",
      "因 為 現 在 ， 我 們 在 得 這 一 時 代 ， 就 是 不 能 相 信 別 人 家 的 很 冷 淡 的 時 代 嘛 ！\n",
      "因 為 現 在 ， 我 們 在 的 這 一 時 代 ， 就 是 不 能 相 信 別 人 家 的 很 冷 淡 的 時 代 嘛 ！\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(1, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "現 在 網 路 已 經 可 以 無 限 上 網 以 及 數 度 變 很 快 ， 網 路 已 經 變 成 無 所 不 在 了 。\n",
      "現 在 網 路 已 經 可 以 無 限 上 網 以 及 數 度 變 很 快 ， 網 路 已 經 變 成 無 所 不 在 了 。\n",
      "現 在 網 路 已 經 可 以 無 限 上 網 以 及 速 度 變 很 快 ， 網 路 已 經 變 成 無 所 不 在 了 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "我 覺 得 裝 這 種 東 西 的 予 算 是 浪 費 ， 這 位 校 長 可 能 只 想 賺 錢 。\n",
      "我 覺 得 裝 這 種 東 西 的 予 算 是 浪 費 ， 這 位 校 長 可 能 只 想 賺 錢 。\n",
      "我 覺 得 裝 這 種 東 西 的 預 算 是 浪 費 ， 這 位 校 長 可 能 只 想 賺 錢 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 8 Loss: 0.16697549779398912\n",
      "nan {'over_corr': 20318, 'total_err': 5278, 'true_corr': tensor(626, device='cuda:0')} {'over_corr': 3239, 'total_err': 3436, 'true_corr': 30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:9/10: 100%|██████████| 147/147 [00:09<00:00, 15.92it/s, loss=0.246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 知 道 每 個 做 父 母 的 人 都 很 關 心 他 們 的 孩 子 ， 然 而 個 遊 客 個 觀 念 ， 每 個 人 都 不 一 樣 。\n",
      "我 知 道 每 個 做 父 母 的 人 都 很 關 心 他 們 的 孩 子 ， 然 而 個 遊 客 個 觀 念 ， 每 個 人 都 不 一 樣 。\n",
      "我 知 道 每 個 做 父 母 的 人 都 很 關 心 他 們 的 孩 子 ， 然 而 各 有 各 的 觀 念 ， 每 個 人 都 不 一 樣 。\n",
      "({'over_corr': 0, 'total_err': 4, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "首 先 請 客 位 讀 者 自 己 想 像 自 己 為 這 所 小 學 的 學 生 。\n",
      "首 先 請 客 位 讀 者 自 己 想 像 自 己 為 這 所 小 學 的 學 生 。\n",
      "首 先 請 各 位 讀 者 自 己 想 像 自 己 為 這 所 小 學 的 學 生 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "因 為 像 人 ， 牠 比 較 小 的 時 候 不 會 記 得 出 了 什 麼 事 ， 所 以 不 會 受 到 心 理 上 的 通 苦 。\n",
      "因 為 像 人 ， 牠 比 較 小 的 時 候 不 會 記 得 出 了 什 麼 事 ， 所 以 不 會 受 到 心 裡 上 的 通 苦 。\n",
      "因 為 像 人 ， 牠 比 較 小 的 時 候 不 會 記 得 出 了 什 麼 事 ， 所 以 不 會 受 到 心 理 上 的 痛 苦 。\n",
      "({'over_corr': 1, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 9 Loss: 0.15459681601345945\n",
      "nan {'over_corr': 25670, 'total_err': 5278, 'true_corr': tensor(586, device='cuda:0')} {'over_corr': 3302, 'total_err': 3436, 'true_corr': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:10/10: 100%|██████████| 147/147 [00:09<00:00, 15.88it/s, loss=0.140]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "「 學 校 黑 網 站 」 不 但 被 欺 負 的 人 的 私 人 隱 私 洩 漏 到 全 校 而 且 洩 漏 到 全 國 ， 甚 至 些 漏 到 全 球 。\n",
      "「 學 校 黑 網 站 」 不 但 被 欺 負 的 人 的 私 人 隱 私 洩 漏 到 全 校 而 且 洩 漏 到 全 國 ， 甚 至 些 漏 到 全 球 。\n",
      "「 學 校 黑 網 站 」 不 但 被 欺 負 的 人 的 私 人 隱 私 洩 漏 到 全 校 而 且 洩 漏 到 全 國 ， 甚 至 洩 漏 到 全 球 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "總 算 是 你 的 公 司 就 交 給 我 ， 可 是 我 要 有 時 間 已 翻 翻 看 我 自 己 的 工 作 ， 以 方 面 練 習 當 老 闆 人 的 方 法 。\n",
      "總 算 是 你 的 公 司 就 交 給 我 ， 可 是 我 要 有 時 間 已 翻 翻 看 我 自 己 的 工 作 ， 以 方 面 練 習 當 老 闆 人 的 方 法 。\n",
      "總 算 是 你 的 公 司 就 交 給 我 ， 可 是 我 要 有 時 間 以 翻 翻 看 我 自 己 的 工 作 ， 一 方 面 練 習 當 老 闆 人 的 方 法 。\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "即 然 我 要 跟 你 見 面 ， 可 是 應 該 幫 他 ， 可 不 可 以 改 天 嗎 ？\n",
      "既 然 我 要 跟 你 見 面 ， 可 是 應 該 幫 他 ， 可 不 可 以 改 天 嗎 ？\n",
      "既 然 我 要 跟 你 見 面 ， 可 是 應 該 幫 他 ， 可 不 可 以 改 天 嗎 ？\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(1, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 1})\n",
      "Epoch 10 Loss: 0.14107231354835081\n",
      "nan {'over_corr': 36321, 'total_err': 5278, 'true_corr': tensor(468, device='cuda:0')} {'over_corr': 3391, 'total_err': 3436, 'true_corr': 7}\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(\n",
    "        enumerate(train_data_loader),\n",
    "        desc=f\"Epoch:{epoch+1}/{epochs}\",\n",
    "        total=len(train_data_loader),\n",
    "    )\n",
    "\n",
    "    for i, batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device).type(torch.float)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, src_mask=attention_mask)\n",
    "        logits = outputs.permute(0, 2, 1)  # (batch_size, vocab_size, seq_len)\n",
    "\n",
    "        # 反向传播在这，故labels不需要传入模型\n",
    "        loss = cross_entropy(logits, labels, ignore_index=tokenizer.pad_token_id)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        progress_bar.set_postfix({\"loss\": \"{:.3f}\".format(loss.item())})\n",
    "\n",
    "    t = torch.argmax(outputs, dim=-1)\n",
    "    nt = t * attention_mask\n",
    "    pred = tokenizer.batch_decode(nt, skip_special_tokens=True)\n",
    "    # print(pred)\n",
    "    # print(f\"origin{tokenizer.batch_decode(labels, skip_special_tokens=True)}\")\n",
    "\n",
    "    for i, v in enumerate(nt):\n",
    "        r, l = input_ids[i], labels[i]\n",
    "        print(tokenizer.decode(r, skip_special_tokens=True))\n",
    "        print(tokenizer.decode(v, skip_special_tokens=True))\n",
    "        print(tokenizer.decode(l, skip_special_tokens=True))\n",
    "        print(cal_err(r, v, l))\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss / len(train_data_loader)}\")\n",
    "    test(model, tokenizer, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ba8cd-90c9-491a-88c6-aab71560aa40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "090f1b7d-394d-4510-b425-901f72548d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.matrices = [\"over_corr\", \"total_err\", \"true_corr\"]\n",
    "\n",
    "    def train(self, dataloader, epoch):\n",
    "        self.iteration(dataloader, epoch)\n",
    "\n",
    "    def test(self, dataloader):\n",
    "        self.iteration(dataloader, train=False)\n",
    "\n",
    "    def iteration(self, dataloader, epochs=1, train=True):\n",
    "        mode = \"train\" if train else \"dev\"\n",
    "        model.train() if train else model.eval()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # matrices\n",
    "            total_loss = 0\n",
    "            char_level = {key: 0 for key in self.matrices}\n",
    "            sent_level = {key: 0 for key in self.matrices}\n",
    "\n",
    "            progress_bar = tqdm(\n",
    "                dataloader,\n",
    "                desc=f\"{mode} Epoch:{epoch+1}/{epochs}\",\n",
    "                total=len(dataloader),\n",
    "            )\n",
    "            for batch in progress_bar:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "\n",
    "                outputs = model(input_ids, src_mask=attention_mask, tgt=labels)\n",
    "                logits = outputs.permute(0, 2, 1)  # (batch_size, vocab_size, seq_len)\n",
    "\n",
    "                loss = cross_entropy(\n",
    "                    logits, labels, ignore_index=tokenizer.pad_token_id\n",
    "                )\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                progress_bar.set_postfix({\"loss\": \"{:.3f}\".format(loss.item())})\n",
    "\n",
    "    def cal_err(raw_sentence, pred_sentence, corr_sentence):\n",
    "        char_level = {key: 0 for key in self.matrices}\n",
    "        sent_level = {key: 0 for key in self.matrices}\n",
    "\n",
    "        for i, c in enumerate(raw_sentence):\n",
    "            pc, cc = pred_sentence[i], corr_sentence[i]\n",
    "            f1 = f2 = False\n",
    "\n",
    "            if cc != c:\n",
    "                char_level[\"total_err\"] += 1\n",
    "                char_level[\"true_corr\"] += pc == cc\n",
    "                f1 = True\n",
    "            elif pc != cc:\n",
    "                char_level[\"over_corr\"] += 1\n",
    "                f2 = True\n",
    "\n",
    "        # true_corr 未计算\n",
    "        sent_level[\"total_err\"] += f1\n",
    "        sent_level[\"over_corr\"] += f2\n",
    "\n",
    "        return char_level, sent_level"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc",
   "language": "python",
   "name": "simple_csc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
