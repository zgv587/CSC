{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bb0c42b-3fa1-4b4c-934a-011db74e01ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T14:53:47.075219Z",
     "iopub.status.busy": "2024-12-06T14:53:47.075219Z",
     "iopub.status.idle": "2024-12-06T14:55:10.404410Z",
     "shell.execute_reply": "2024-12-06T14:55:10.404410Z",
     "shell.execute_reply.started": "2024-12-06T14:53:47.075219Z"
    }
   },
   "outputs": [],
   "source": [
    "from config import *\n",
    "from data_processer import CSCDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11950720-5407-4506-b59e-deea88907b77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T14:55:10.405417Z",
     "iopub.status.busy": "2024-12-06T14:55:10.405417Z",
     "iopub.status.idle": "2024-12-06T14:55:27.846169Z",
     "shell.execute_reply": "2024-12-06T14:55:27.846169Z",
     "shell.execute_reply.started": "2024-12-06T14:55:10.405417Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    BertForSequenceClassification,\n",
    "    BertTokenizer,\n",
    "    get_scheduler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d2e5bf-2644-4f7b-8fbe-6aef5b5ff9a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T14:55:27.847181Z",
     "iopub.status.busy": "2024-12-06T14:55:27.847181Z",
     "iopub.status.idle": "2024-12-06T14:55:27.868567Z",
     "shell.execute_reply": "2024-12-06T14:55:27.868567Z",
     "shell.execute_reply.started": "2024-12-06T14:55:27.847181Z"
    }
   },
   "outputs": [],
   "source": [
    "# matrices\n",
    "def cal_err(raw_sentence, pred_sentence, corr_sentence):\n",
    "    matrices = [\"over_corr\", \"total_err\", \"true_corr\"]\n",
    "\n",
    "    char_level = {key: 0 for key in matrices}\n",
    "    sent_level = {key: 0 for key in matrices}\n",
    "\n",
    "    for i, c in enumerate(raw_sentence):\n",
    "        pc, cc = pred_sentence[i], corr_sentence[i]\n",
    "        f1 = f2 = False\n",
    "\n",
    "        if cc != c:\n",
    "            char_level[\"total_err\"] += 1\n",
    "            char_level[\"true_corr\"] += pc == cc\n",
    "            f1 = True\n",
    "        elif pc != cc:\n",
    "            char_level[\"over_corr\"] += 1\n",
    "            f2 = True\n",
    "\n",
    "    # true_corr 未计算\n",
    "    sent_level[\"total_err\"] += f1\n",
    "    sent_level[\"over_corr\"] += f2\n",
    "\n",
    "    return char_level, sent_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b29704ad-c868-49b1-af1e-845de0d659d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T14:55:27.869578Z",
     "iopub.status.busy": "2024-12-06T14:55:27.869578Z",
     "iopub.status.idle": "2024-12-06T14:55:27.874596Z",
     "shell.execute_reply": "2024-12-06T14:55:27.874596Z",
     "shell.execute_reply.started": "2024-12-06T14:55:27.869578Z"
    }
   },
   "outputs": [],
   "source": [
    "def cal_err(raw_sentence, pred_sentence, corr_sentence):\n",
    "    matrices = [\"over_corr\", \"total_err\", \"true_corr\"]\n",
    "    char_level = {key: 0 for key in matrices}\n",
    "    sent_level = {key: 0 for key in matrices}\n",
    "\n",
    "    for i, c in enumerate(raw_sentence):\n",
    "        pc, cc = pred_sentence[i], corr_sentence[i]\n",
    "        f1 = f2 = 0\n",
    "\n",
    "        if cc != c:\n",
    "            char_level[\"total_err\"] += 1\n",
    "            char_level[\"true_corr\"] += pc == cc\n",
    "            f1 = 1\n",
    "        elif pc != cc:\n",
    "            char_level[\"over_corr\"] += 1\n",
    "            f2 = 1\n",
    "\n",
    "    # true_corr 未计算\n",
    "    sent_level[\"total_err\"] += f1\n",
    "    sent_level[\"over_corr\"] += f2\n",
    "\n",
    "    return char_level, sent_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72747c97-3c76-4b65-8402-7d507c022b85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T14:55:27.875600Z",
     "iopub.status.busy": "2024-12-06T14:55:27.875600Z",
     "iopub.status.idle": "2024-12-06T14:55:27.895470Z",
     "shell.execute_reply": "2024-12-06T14:55:27.895470Z",
     "shell.execute_reply.started": "2024-12-06T14:55:27.875600Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, tokenizer, test_data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    matrices = [\"over_corr\", \"total_err\", \"true_corr\"]\n",
    "    test_char_level = {key: 0 for key in matrices}\n",
    "    test_sent_level = {key: 0 for key in matrices}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_data_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device).type(torch.float)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, src_mask=attention_mask)\n",
    "            logits = outputs.permute(0, 2, 1)\n",
    "\n",
    "            loss = cross_entropy(logits, labels, ignore_index=tokenizer.pad_token_id)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            t = torch.argmax(outputs, dim=-1)\n",
    "            nt = t * attention_mask\n",
    "            pred = tokenizer.batch_decode(nt, skip_special_tokens=True)\n",
    "\n",
    "            for i in range(len(t)):\n",
    "                char_level, sent_level = cal_err(input_ids[i], nt[i], labels[i])\n",
    "                test_char_level = {\n",
    "                    key: test_char_level[key] + v for key, v in char_level.items()\n",
    "                }\n",
    "                test_sent_level = {\n",
    "                    key: test_sent_level[key] + v for key, v in sent_level.items()\n",
    "                }\n",
    "        print(total_loss / len(test_data_loader), test_char_level, test_sent_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cddc97a-3f74-423b-b057-7cb0aa81c325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T14:55:27.896489Z",
     "iopub.status.busy": "2024-12-06T14:55:27.896489Z",
     "iopub.status.idle": "2024-12-06T15:47:25.927883Z",
     "shell.execute_reply": "2024-12-06T15:47:25.923879Z",
     "shell.execute_reply.started": "2024-12-06T14:55:27.896489Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocessing sighan dataset: 2339it [00:00, 77618.22it/s]\n",
      "preprocessing sighan dataset: 100%|███████████████████████████████████████████| 2339/2339 [00:00<00:00, 1172660.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共2339句，共73264字，最长的句子有171字\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocessing sighan dataset: 3437it [00:00, 686467.75it/s]\n",
      "preprocessing sighan dataset: 100%|███████████████████████████████████████████| 3437/3437 [00:00<00:00, 1145112.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共3437句，共170330字，最长的句子有258字\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\csc_env\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch:1/10: 100%|████████████████████████████████████████████████████████| 585/585 [01:12<00:00,  8.12it/s, loss=0.588]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 有 明 天 的 工 課 ， 這 個 晚 上 請 您 給 我 打 電 話 。\n",
      "我 有 明 天 的 工 課 ， 這 個 晚 上 請 您 給 我 打 電 話 。\n",
      "我 有 明 天 的 功 課 ， 這 個 晚 上 請 您 給 我 打 電 話 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "我 老 婆 的 公 司 上 禮 拜 也 破 產 了 ， 她 現 在 也 沒 有 工 作 了 ， 只 好 在 家 照 顧 小 孩 。 在 這 樣 的 情 況 下 讓 我 授 到 更 大 的 壓 力 。\n",
      "我 老 到 的 公 司 上 禮 拜 也 話 產 了 ， 她 現 在 也 沒 有 工 作 了 ， 只 好 在 家 照 顧 小 孩 。 在 這 樣 的 情 況 下 讓 我 已 到 更 大 的 壓 力 。\n",
      "我 老 婆 的 公 司 上 禮 拜 也 破 產 了 ， 她 現 在 也 沒 有 工 作 了 ， 只 好 在 家 照 顧 小 孩 。 在 這 樣 的 情 況 下 讓 我 受 到 更 大 的 壓 力 。\n",
      "({'over_corr': 2, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "里 先 生 ， 我 們 在 這 每 天 都 要 做 生 意 ， 客 人 往 來 很 多 。\n",
      "不 先 生 ， 我 們 在 這 每 天 都 要 做 生 意 ， 客 人 往 來 很 多 。\n",
      "李 先 生 ， 我 們 在 這 每 天 都 要 做 生 意 ， 客 人 往 來 很 多 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "Epoch 1 Loss: 2.4641496965008924\n",
      "0.9861881469224775 {'over_corr': 12560, 'total_err': 5278, 'true_corr': tensor(235, device='cuda:0')} {'over_corr': 0, 'total_err': 0, 'true_corr': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:2/10: 100%|████████████████████████████████████████████████████████| 585/585 [01:07<00:00,  8.64it/s, loss=0.502]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "媽 媽 說 ： 「 為 什 麼 這 個 事 情 會 讓 他 怎 麼 難 過 呢 ？ 」\n",
      "媽 媽 說 ： 「 為 什 麼 這 個 事 情 會 讓 他 怎 麼 難 過 呢 ？ 」\n",
      "媽 媽 說 ： 「 為 什 麼 這 個 事 情 會 讓 他 這 麼 難 過 呢 ？ 」\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "有 別 的 現 代 工 廠 失 出 了 這 兩 個 效 果 ， 你 可 以 採 用 他 們 的 辦 法 。\n",
      "有 別 的 現 代 工 廠 失 出 了 這 兩 個 效 果 ， 你 可 以 這 用 他 們 的 辦 法 。\n",
      "有 別 的 現 代 工 廠 使 出 了 這 兩 個 效 果 ， 你 可 以 採 用 他 們 的 辦 法 。\n",
      "({'over_corr': 1, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "優 秀 學 生 讀 錢 多 的 係 ， 可 是 常 常 不 是 他 們 所 愛 的 科 目 ， 這 就 照 成 問 題 。\n",
      "優 分 學 生 讀 錢 多 的 係 ， 可 是 常 常 不 是 他 們 所 愛 的 科 目 ， 這 就 照 成 問 題 。\n",
      "優 秀 學 生 讀 錢 多 的 系 ， 可 是 常 常 不 是 他 們 所 愛 的 科 目 ， 這 就 照 成 問 題 。\n",
      "({'over_corr': 1, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "Epoch 2 Loss: 0.6973791969382864\n",
      "0.6494277080217766 {'over_corr': 6871, 'total_err': 5278, 'true_corr': tensor(311, device='cuda:0')} {'over_corr': 0, 'total_err': 0, 'true_corr': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:3/10: 100%|████████████████████████████████████████████████████████| 585/585 [01:20<00:00,  7.28it/s, loss=0.278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "對 不 起 ， 我 不 能 參 加 你 開 的 慶 祝 會 ， 因 為 我 有 事 情 。 但 是 我 一 定 送 給 你 一 把 很 大 的 化 。\n",
      "對 不 起 ， 我 不 能 參 加 你 開 的 慶 祝 會 ， 因 為 我 有 事 情 。 但 是 我 一 定 送 給 你 一 把 很 大 的 化 。\n",
      "對 不 起 ， 我 不 能 參 加 你 開 的 慶 祝 會 ， 因 為 我 有 事 情 。 但 是 我 一 定 送 給 你 一 把 很 大 的 花 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "要 是 您 們 把 這 問 題 方 在 一 邊 不 理 ！ 我 們 會 向 法 院 起 訴 。\n",
      "要 是 您 們 把 這 問 題 方 在 一 邊 不 理 ！ 我 們 會 向 法 院 起 訴 。\n",
      "要 是 您 們 把 這 問 題 放 在 一 邊 不 理 ！ 我 們 會 向 法 院 起 訴 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "我 寫 這 豐 電 子 郵 件 問 你 ， 現 在 你 的 身 體 怎 麼 樣 了 ？\n",
      "我 寫 這 做 電 子 到 件 問 你 ， 現 在 你 的 身 體 怎 麼 樣 了 ？\n",
      "我 寫 這 封 電 子 郵 件 問 你 ， 現 在 你 的 身 體 怎 麼 樣 了 ？\n",
      "({'over_corr': 1, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "Epoch 3 Loss: 0.47670051298844507\n",
      "0.5215529998721078 {'over_corr': 4974, 'total_err': 5278, 'true_corr': tensor(399, device='cuda:0')} {'over_corr': 0, 'total_err': 0, 'true_corr': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:4/10: 100%|████████████████████████████████████████████████████████| 585/585 [01:36<00:00,  6.08it/s, loss=0.193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最 近 在 新 聞 長 報 導 說 很 多 小 孩 兒 跳 樓 自 殺 ， 原 因 是 因 為 達 不 到 父 母 的 要 求 。\n",
      "最 近 在 新 聞 長 報 導 說 很 多 小 孩 兒 跳 樓 自 殺 ， 原 因 是 因 為 達 不 到 父 母 的 要 求 。\n",
      "最 近 在 新 聞 常 報 導 說 很 多 小 孩 兒 跳 樓 自 殺 ， 原 因 是 因 為 達 不 到 父 母 的 要 求 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "因 為 如 果 你 們 的 展 品 讓 我 們 的 身 體 有 問 題 我 們 一 定 不 會 支 持 你 們 ， 所 以 我 們 希 望 你 們 能 處 理 你 們 工 廠 的 噪 音 和 臭 味 。\n",
      "因 為 如 果 你 們 的 展 品 讓 我 們 的 身 體 有 問 題 我 們 一 定 不 會 支 持 你 們 ， 所 以 我 們 希 望 你 們 能 處 理 你 們 工 廠 的 噪 音 和 臭 味 。\n",
      "因 為 如 果 你 們 的 產 品 讓 我 們 的 身 體 有 問 題 我 們 一 定 不 會 支 持 你 們 ， 所 以 我 們 希 望 你 們 能 處 理 你 們 工 廠 的 噪 音 和 臭 味 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "這 幾 天 ， 我 們 的 鄰 區 一 個 一 個 地 來 跟 我 煩 惱 。\n",
      "這 幾 天 ， 我 們 的 鄰 居 一 個 一 個 地 來 跟 我 煩 惱 。\n",
      "這 幾 天 ， 我 們 的 鄰 居 一 個 一 個 地 來 跟 我 煩 惱 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(1, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "Epoch 4 Loss: 0.3732189028563663\n",
      "0.4628086401539486 {'over_corr': 4056, 'total_err': 5278, 'true_corr': tensor(322, device='cuda:0')} {'over_corr': 0, 'total_err': 0, 'true_corr': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:5/10: 100%|████████████████████████████████████████████████████████| 585/585 [01:44<00:00,  5.61it/s, loss=0.360]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "過 了 三 十 分 鐘 后 ， 下 著 雨 了 ！\n",
      "過 了 三 十 分 鐘 後 ， 下 著 雨 了 ！\n",
      "過 了 三 十 分 鐘 後 ， 下 著 雨 了 ！\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(1, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "凱 鈞 那 天 對 我 很 好 ， 請 我 座 在 沙 發 上 ， 然 後 就 去 了 廚 房 幫 我 們 從 冰 箱 裡 拿 飲 料 和 餅 乾 。\n",
      "驚 好 那 天 對 我 很 好 ， 請 我 坐 在 沙 發 上 ， 然 後 就 去 了 廚 房 幫 我 們 從 冰 箱 裡 拿 飲 料 和 餅 乾 。\n",
      "凱 鈞 那 天 對 我 很 好 ， 請 我 坐 在 沙 發 上 ， 然 後 就 去 了 廚 房 幫 我 們 從 冰 箱 裡 拿 飲 料 和 餅 乾 。\n",
      "({'over_corr': 2, 'total_err': 1, 'true_corr': tensor(1, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "我 想 因 為 太 多 想 要 養 狗 的 人 他 們 想 要 就 養 沒 有 考 慮 到 養 狗 的 麻 煩 ， 所 以 發 見 沒 辦 法 養 狗 就 悼 在 河 邊 。\n",
      "我 想 因 為 太 多 想 要 養 狗 的 人 他 們 想 要 就 養 沒 有 考 慮 到 養 狗 的 麻 煩 ， 所 以 發 見 沒 辦 法 養 狗 就 掉 在 河 邊 。\n",
      "我 想 因 為 太 多 想 要 養 狗 的 人 他 們 想 要 就 養 沒 有 考 慮 到 養 狗 的 麻 煩 ， 所 以 發 現 沒 辦 法 養 狗 就 掉 在 河 邊 。\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(1, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "Epoch 5 Loss: 0.3083474878954072\n",
      "0.42362425940674403 {'over_corr': 3513, 'total_err': 5278, 'true_corr': tensor(434, device='cuda:0')} {'over_corr': 0, 'total_err': 0, 'true_corr': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:6/10: 100%|████████████████████████████████████████████████████████| 585/585 [01:47<00:00,  5.45it/s, loss=0.255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "上 次 我 們 舉 辦 理 會 的 時 候 ， 一 個 代 表 委 員 提 出 一 個 意 見 關 於 貴 工 廠 的 。\n",
      "上 次 我 們 舉 辦 理 會 的 時 候 ， 一 個 代 表 委 員 提 出 一 個 意 見 關 於 貴 工 廠 的 。\n",
      "上 次 我 們 舉 辦 里 會 的 時 候 ， 一 個 代 表 委 員 提 出 一 個 意 見 關 於 貴 工 廠 的 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "因 為 人 的 生 活 很 短 如 果 可 以 一 邊 讀 書 一 邊 工 作 就 表 示 我 們 更 走 的 快 ， 更 找 得 到 自 己 喜 歡 的 職 業 ， 更 專 門 ， 更 有 經 驗 。\n",
      "因 為 人 的 生 活 很 短 如 果 可 以 一 邊 讀 書 一 邊 工 作 就 表 示 我 們 更 走 的 快 ， 更 找 得 到 自 己 喜 歡 的 職 業 ， 更 專 門 ， 更 有 經 驗 。\n",
      "因 為 人 的 生 活 很 短 如 果 可 以 一 邊 讀 書 一 邊 工 作 就 表 示 我 們 更 走 得 快 ， 更 找 得 到 自 己 喜 歡 的 職 業 ， 更 專 門 ， 更 有 經 驗 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "跟 您 將 電 話 時 ， 當 時 我 好 擔 心 您 ， 以 後 我 想 一 想 我 們 要 怎 麼 辦 。\n",
      "跟 您 將 電 話 時 ， 當 時 我 好 擔 心 您 ， 以 後 我 想 一 想 我 們 要 怎 麼 辦 。\n",
      "跟 您 講 電 話 時 ， 當 時 我 好 擔 心 您 ， 以 後 我 想 一 想 我 們 要 怎 麼 辦 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "Epoch 6 Loss: 0.25905570648928994\n",
      "0.40223410396381865 {'over_corr': 3174, 'total_err': 5278, 'true_corr': tensor(451, device='cuda:0')} {'over_corr': 0, 'total_err': 0, 'true_corr': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:7/10: 100%|████████████████████████████████████████████████████████| 585/585 [01:37<00:00,  6.00it/s, loss=0.302]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "美 國 現 在 很 冷 ， 請 辦 我 買 件 雪 衣 。\n",
      "美 國 現 在 很 冷 ， 請 辦 我 買 件 學 衣 。\n",
      "美 國 現 在 很 冷 ， 請 幫 我 買 件 雪 衣 。\n",
      "({'over_corr': 1, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "現 代 社 會 的 學 生 們 大 多 數 是 早 熟 而 且 在 經 濟 方 面 也 好 ， 他 們 是 信 眾 帶 著 很 多 渴 望 比 如 說 有 權 力 的 學 生 很 想 行 駛 他 們 的 權 力 ， 有 錢 的 學 生 想 像 同 學 們 炫 耀 他 們 的 財 富 。\n",
      "現 代 社 會 的 學 生 們 大 多 數 是 早 熟 而 且 在 經 濟 方 面 也 好 ， 他 們 是 信 眾 帶 著 很 多 送 望 比 如 說 有 權 力 的 學 生 很 想 行 經 他 們 的 權 力 ， 有 錢 的 學 生 想 像 同 學 們 炫 耀 他 們 的 財 富 。\n",
      "現 代 社 會 的 學 生 們 大 多 數 是 早 熟 而 且 在 經 濟 方 面 也 好 ， 他 們 是 信 眾 帶 著 很 多 渴 望 比 如 說 有 權 力 的 學 生 很 想 行 使 他 們 的 權 力 ， 有 錢 的 學 生 想 向 同 學 們 炫 耀 他 們 的 財 富 。\n",
      "({'over_corr': 1, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "這 次 的 全 球 經 濟 衰 退 ， 對 我 來 說 也 有 影 響 ， 使 得 新 水 減 少 、 工 作 天 數 變 少 等 。\n",
      "這 次 的 全 球 經 濟 衰 退 ， 對 我 來 說 也 有 影 響 ， 使 得 新 水 減 少 、 工 作 天 數 變 少 等 。\n",
      "這 次 的 全 球 經 濟 衰 退 ， 對 我 來 說 也 有 影 響 ， 使 得 薪 水 減 少 、 工 作 天 數 變 少 等 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "Epoch 7 Loss: 0.21840260915267162\n",
      "0.38293532033905736 {'over_corr': 2523, 'total_err': 5278, 'true_corr': tensor(456, device='cuda:0')} {'over_corr': 0, 'total_err': 0, 'true_corr': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:8/10: 100%|████████████████████████████████████████████████████████| 585/585 [01:35<00:00,  6.13it/s, loss=0.174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有 一 天 他 問 我 朋 友 的 手 機 號 碼 ， 我 的 朋 友 可 以 告 訴 他 號 嗎 因 為 相 信 他 。\n",
      "有 一 天 他 問 我 朋 友 的 手 機 號 碼 ， 我 的 朋 友 可 以 告 訴 他 號 媽 因 為 相 信 他 。\n",
      "有 一 天 他 問 我 朋 友 的 手 機 號 碼 ， 我 的 朋 友 可 以 告 訴 他 號 碼 因 為 相 信 他 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "他 看 到 了 一 輛 紅 汽 車 ， 就 決 定 叫 那 個 人 定 車 。\n",
      "他 看 到 了 一 輛 紅 汽 車 ， 就 決 定 叫 那 個 人 定 車 。\n",
      "他 看 到 了 一 輛 紅 汽 車 ， 就 決 定 叫 那 個 人 停 車 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "由 於 年 紀 已 經 不 輕 ， 所 以 要 再 從 新 找 一 份 工 作 ， 對 他 來 說 是 如 此 艱 難 的 事 啊 ！\n",
      "由 於 年 紀 已 經 不 輕 ， 所 以 要 再 從 新 找 一 份 工 作 ， 對 他 來 說 是 如 此 艱 難 的 事 啊 ！\n",
      "由 於 年 紀 已 經 不 輕 ， 所 以 要 再 重 新 找 一 份 工 作 ， 對 他 來 說 是 如 此 艱 難 的 事 啊 ！\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "Epoch 8 Loss: 0.18372087489463326\n",
      "0.37691865138016467 {'over_corr': 2528, 'total_err': 5278, 'true_corr': tensor(458, device='cuda:0')} {'over_corr': 0, 'total_err': 0, 'true_corr': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:9/10: 100%|████████████████████████████████████████████████████████| 585/585 [01:37<00:00,  6.02it/s, loss=0.212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你 的 公 交 孩 子 真 實 是 普 通 的 事 況 ， 但 是 我 自 己 又 已 經 有 了 生 計 畫 ， 所 以 現 在 沒 辦 法 去 做 控 制 你 的 公 司 。\n",
      "你 的 公 交 孩 子 真 實 是 普 通 的 事 況 ， 但 是 我 自 己 又 已 經 有 了 生 計 畫 ， 所 以 現 在 沒 辦 法 去 做 控 制 你 的 公 司 。\n",
      "你 的 公 交 孩 子 真 實 是 普 通 的 事 況 ， 但 是 我 自 己 又 已 經 有 人 生 計 畫 ， 所 以 現 在 沒 辦 法 去 做 控 制 你 的 公 司 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "今 天 大 明 第 一 次 到 十 大 去 ， 他 是 新 生 在 師 大 。\n",
      "今 天 大 明 第 一 次 到 十 大 去 ， 他 是 新 生 在 師 大 。\n",
      "今 天 大 明 第 一 次 到 師 大 去 ， 他 是 新 生 在 師 大 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "她 教 我 怎 嗎 去 學 校 了 。\n",
      "她 教 我 怎 麼 去 學 校 了 。\n",
      "她 教 我 怎 麼 去 學 校 了 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(1, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "Epoch 9 Loss: 0.15384562173460284\n",
      "0.37297898604599544 {'over_corr': 2578, 'total_err': 5278, 'true_corr': tensor(492, device='cuda:0')} {'over_corr': 0, 'total_err': 0, 'true_corr': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:10/10: 100%|███████████████████████████████████████████████████████| 585/585 [01:42<00:00,  5.68it/s, loss=0.192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "這 個 旅 行 是 天 兩 夜 ， 印 度 的 南 部 很 漂 亮 ， 風 景 也 很 美 。\n",
      "這 個 旅 行 是 天 兩 夜 ， 印 度 的 南 部 很 漂 亮 ， 風 景 也 很 美 。\n",
      "這 個 旅 行 四 天 兩 夜 ， 印 度 的 南 部 很 漂 亮 ， 風 景 也 很 美 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "他 從 半 年 前 起 ， 一 直 在 醫 院 裡 ， 可 能 她 將 來 會 沒 希 望 了 。 如 果 他 死 掉 的 ， 你 能 負 責 任 嗎 ？\n",
      "他 從 半 年 前 起 ， 一 直 在 醫 院 裡 ， 可 能 她 將 來 會 沒 希 望 了 。 如 果 他 死 掉 的 ， 你 能 負 責 任 嗎 ？\n",
      "他 從 半 年 前 起 ， 一 直 在 醫 院 裡 ， 可 能 她 將 來 會 沒 希 望 了 。 如 果 他 死 掉 了 ， 你 能 負 責 任 嗎 ？\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "醫 生 跟 他 說 ： 你 一 定 最 少 每 個 星 期 運 動 兩 次 ， 要 不 然 你 的 身 體 不 輸 服 ， 你 的 頭 會 容 易 疼 。\n",
      "醫 生 跟 他 說 ： 你 一 定 最 少 每 個 星 期 運 動 兩 次 ， 要 不 然 你 的 身 體 不 輸 服 ， 你 的 頭 會 容 易 疼 。\n",
      "醫 生 跟 他 說 ： 你 一 定 最 少 每 個 星 期 運 動 兩 次 ， 要 不 然 你 的 身 體 不 舒 服 ， 你 的 頭 會 容 易 疼 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 0, 'true_corr': 0})\n",
      "Epoch 10 Loss: 0.1255169694749718\n",
      "0.3688472471091636 {'over_corr': 2611, 'total_err': 5278, 'true_corr': tensor(514, device='cuda:0')} {'over_corr': 0, 'total_err': 0, 'true_corr': 0}\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "from models import Seq2SeqModel\n",
    "from torch.nn.functional import cross_entropy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# temp_data\n",
    "nhead = 4  # 多头注意力机制的头数\n",
    "num_decoder_layers = 2\n",
    "dim_feedforward = 3072\n",
    "max_seq_len = 128\n",
    "dropout = 0.1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tokenizer = BertTokenizer.from_pretrained(checkpoint)\n",
    "    bert = BertModel.from_pretrained(checkpoint)\n",
    "\n",
    "    train_dataset = CSCDataset([SIGHAN_train_dir_err, SIGHAN_train_dir_corr], tokenizer)\n",
    "    train_data_loader = DataLoader(\n",
    "        train_dataset, num_workers=0, shuffle=True, batch_size=8\n",
    "    )\n",
    "\n",
    "    test_dataset = CSCDataset(\n",
    "        [SIGHAN_train_dir_err14, SIGHAN_train_dir_corr14], tokenizer\n",
    "    )\n",
    "    test_data_loader = DataLoader(\n",
    "        test_dataset, num_workers=0, shuffle=True, batch_size=4\n",
    "    )\n",
    "\n",
    "    model = Seq2SeqModel(\n",
    "        bert, nhead, num_decoder_layers, dim_feedforward, max_seq_len, dropout\n",
    "    )\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(\n",
    "            enumerate(train_data_loader),\n",
    "            desc=f\"Epoch:{epoch+1}/{epochs}\",\n",
    "            total=len(train_data_loader),\n",
    "        )\n",
    "\n",
    "        for i, batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device).type(torch.float)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, src_mask=attention_mask)\n",
    "            logits = outputs.permute(0, 2, 1)  # (batch_size, vocab_size, seq_len)\n",
    "\n",
    "            # 反向传播在这，故labels不需要传入模型\n",
    "            loss = cross_entropy(logits, labels, ignore_index=tokenizer.pad_token_id)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            progress_bar.set_postfix({\"loss\": \"{:.3f}\".format(loss.item())})\n",
    "\n",
    "        t = torch.argmax(outputs, dim=-1)\n",
    "        nt = t * attention_mask\n",
    "        pred = tokenizer.batch_decode(nt, skip_special_tokens=True)\n",
    "        # print(pred)\n",
    "        # print(f\"origin{tokenizer.batch_decode(labels, skip_special_tokens=True)}\")\n",
    "\n",
    "        for i, v in enumerate(nt):\n",
    "            r, l = input_ids[i], labels[i]\n",
    "            print(tokenizer.decode(r, skip_special_tokens=True))\n",
    "            print(tokenizer.decode(v, skip_special_tokens=True))\n",
    "            print(tokenizer.decode(l, skip_special_tokens=True))\n",
    "            print(cal_err(r, v, l))\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss / len(train_data_loader)}\")\n",
    "        test(model, tokenizer, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f485237-bafa-452c-b127-2a2daeb44b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3de74fe-d045-4cf5-a67a-69e54d8c5f06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T15:47:25.933901Z",
     "iopub.status.busy": "2024-12-06T15:47:25.932884Z",
     "iopub.status.idle": "2024-12-06T15:47:26.916028Z",
     "shell.execute_reply": "2024-12-06T15:47:26.916028Z",
     "shell.execute_reply.started": "2024-12-06T15:47:25.933901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: 这是个测试句子。\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Seq2SeqModel.forward() got an unexpected keyword argument 'tgt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m test_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m这是个测试句子。\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Sentence:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_sentence)\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorrected Sentence:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_sentence\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[7], line 24\u001b[0m, in \u001b[0;36mtest_model\u001b[1;34m(model, tokenizer, text, max_length)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     23\u001b[0m     tgt_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(decoded_indices)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 24\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     next_token_logits \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :, :]\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     26\u001b[0m     next_token_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(next_token_logits)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\csc_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\csc_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mTypeError\u001b[0m: Seq2SeqModel.forward() got an unexpected keyword argument 'tgt'"
     ]
    }
   ],
   "source": [
    "# 测试函数\n",
    "def test_model(model, tokenizer, text, max_length=128):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        input_ids = inputs[\"input_ids\"].to(device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "        # Start with the special token [CLS]\n",
    "        start_token = tokenizer.cls_token_id\n",
    "        decoded_indices = [start_token]\n",
    "\n",
    "        for _ in range(max_length - 1):\n",
    "            tgt_tensor = torch.tensor(decoded_indices).unsqueeze(1).to(device)\n",
    "            outputs = model(input_ids, tgt=tgt_tensor, src_mask=attention_mask)\n",
    "            next_token_logits = outputs[-1, :, :].squeeze()\n",
    "            next_token_id = torch.argmax(next_token_logits).item()\n",
    "\n",
    "            if next_token_id == tokenizer.sep_token_id:\n",
    "                break\n",
    "\n",
    "            decoded_indices.append(next_token_id)\n",
    "\n",
    "        corrected_text = tokenizer.decode(decoded_indices, skip_special_tokens=True)\n",
    "        return corrected_text\n",
    "\n",
    "\n",
    "# 测试\n",
    "test_sentence = \"这是个测试句子。\"\n",
    "print(\"Original Sentence:\", test_sentence)\n",
    "print(\"Corrected Sentence:\", test_model(model, tokenizer, test_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ba8cd-90c9-491a-88c6-aab71560aa40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090f1b7d-394d-4510-b425-901f72548d1d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-06T15:47:26.917037Z",
     "iopub.status.idle": "2024-12-06T15:47:26.917037Z",
     "shell.execute_reply": "2024-12-06T15:47:26.917037Z",
     "shell.execute_reply.started": "2024-12-06T15:47:26.917037Z"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.matrices = [\"over_corr\", \"total_err\", \"true_corr\"]\n",
    "\n",
    "    def train(self, dataloader, epoch):\n",
    "        self.iteration(dataloader, epoch)\n",
    "\n",
    "    def test(self, dataloader):\n",
    "        self.iteration(dataloader, train=False)\n",
    "\n",
    "    def iteration(self, dataloader, epochs=1, train=True):\n",
    "        mode = \"train\" if train else \"dev\"\n",
    "        model.train() if train else model.eval()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # matrices\n",
    "            total_loss = 0\n",
    "            char_level = {key: 0 for key in self.matrices}\n",
    "            sent_level = {key: 0 for key in self.matrices}\n",
    "\n",
    "            progress_bar = tqdm(\n",
    "                dataloader,\n",
    "                desc=f\"{mode} Epoch:{epoch+1}/{epochs}\",\n",
    "                total=len(dataloader),\n",
    "            )\n",
    "            for batch in progress_bar:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "\n",
    "                outputs = model(input_ids, src_mask=attention_mask, tgt=labels)\n",
    "                logits = outputs.permute(0, 2, 1)  # (batch_size, vocab_size, seq_len)\n",
    "\n",
    "                loss = cross_entropy(\n",
    "                    logits, labels, ignore_index=tokenizer.pad_token_id\n",
    "                )\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                progress_bar.set_postfix({\"loss\": \"{:.3f}\".format(loss.item())})\n",
    "\n",
    "    def cal_err(raw_sentence, pred_sentence, corr_sentence):\n",
    "        char_level = {key: 0 for key in self.matrices}\n",
    "        sent_level = {key: 0 for key in self.matrices}\n",
    "\n",
    "        for i, c in enumerate(raw_sentence):\n",
    "            pc, cc = pred_sentence[i], corr_sentence[i]\n",
    "            f1 = f2 = False\n",
    "\n",
    "            if cc != c:\n",
    "                char_level[\"total_err\"] += 1\n",
    "                char_level[\"true_corr\"] += pc == cc\n",
    "                f1 = True\n",
    "            elif pc != cc:\n",
    "                char_level[\"over_corr\"] += 1\n",
    "                f2 = True\n",
    "\n",
    "        # true_corr 未计算\n",
    "        sent_level[\"total_err\"] += f1\n",
    "        sent_level[\"over_corr\"] += f2\n",
    "\n",
    "        return char_level, sent_level"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc_env",
   "language": "python",
   "name": "csc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
