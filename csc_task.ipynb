{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bb0c42b-3fa1-4b4c-934a-011db74e01ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/simple_csc/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "from data_processer import CSCDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11950720-5407-4506-b59e-deea88907b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    BertForSequenceClassification,\n",
    "    BertTokenizer,\n",
    "    get_scheduler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b29704ad-c868-49b1-af1e-845de0d659d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_err(raw_sentence, pred_sentence, corr_sentence):\n",
    "    matrices = [\"over_corr\", \"total_err\", \"true_corr\"]\n",
    "    char_level = {key: 0 for key in matrices}\n",
    "    sent_level = {key: 0 for key in matrices}\n",
    "\n",
    "    f1 = f2 = 0\n",
    "    for i, c in enumerate(raw_sentence):\n",
    "        pc, cc = pred_sentence[i], corr_sentence[i]\n",
    "\n",
    "        if cc != c:\n",
    "            char_level[\"total_err\"] += 1\n",
    "            char_level[\"true_corr\"] += pc == cc\n",
    "            f1 = 1\n",
    "        elif pc != cc:\n",
    "            char_level[\"over_corr\"] += 1\n",
    "            f2 = 1\n",
    "\n",
    "    if f1:\n",
    "        sent_level[\"true_corr\"] += all(pred_sentence == corr_sentence)\n",
    "        sent_level[\"total_err\"] += f1\n",
    "    sent_level[\"over_corr\"] += f2\n",
    "\n",
    "    return char_level, sent_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72747c97-3c76-4b65-8402-7d507c022b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, tokenizer, test_data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    matrices = [\"over_corr\", \"total_err\", \"true_corr\"]\n",
    "    test_char_level = {key: 0 for key in matrices}\n",
    "    test_sent_level = {key: 0 for key in matrices}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_data_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device).type(torch.float)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, src_mask=attention_mask)\n",
    "            logits = outputs.permute(0, 2, 1)\n",
    "\n",
    "            loss = cross_entropy(logits, labels, ignore_index=tokenizer.pad_token_id)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            t = torch.argmax(outputs, dim=-1)\n",
    "            nt = t * attention_mask\n",
    "            pred = tokenizer.batch_decode(nt, skip_special_tokens=True)\n",
    "\n",
    "            for i in range(len(t)):\n",
    "                char_level, sent_level = cal_err(input_ids[i], nt[i], labels[i])\n",
    "                test_char_level = {\n",
    "                    key: test_char_level[key] + v for key, v in char_level.items()\n",
    "                }\n",
    "                test_sent_level = {\n",
    "                    key: test_sent_level[key] + v for key, v in sent_level.items()\n",
    "                }\n",
    "        print(total_loss / len(test_data_loader), test_char_level, test_sent_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cddc97a-3f74-423b-b057-7cb0aa81c325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocessing sighan dataset: 2339it [00:00, 921085.07it/s]\n",
      "preprocessing sighan dataset: 100%|██████████| 2339/2339 [00:00<00:00, 1635079.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共2339句，共73264字，最长的句子有171字\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocessing sighan dataset: 3437it [00:00, 912509.36it/s]\n",
      "preprocessing sighan dataset: 100%|██████████| 3437/3437 [00:00<00:00, 1333193.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共3437句，共170330字，最长的句子有258字\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/simple_csc/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch:1/10: 100%|██████████| 147/147 [00:11<00:00, 13.22it/s, loss=2.377]\n",
      "/root/anaconda3/envs/simple_csc/lib/python3.10/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 門 下 個 裡 俳 才 去 看 電 影 可 以 嗎 ？\n",
      "我 ， 下 個 裡 得 才 去 看 電 影 可 以 嗎 ？\n",
      "我 們 下 個 禮 拜 才 去 看 電 影 可 以 嗎 ？\n",
      "({'over_corr': 0, 'total_err': 3, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "隨 著 科 學 技 術 地 發 展 ， 電 腦 是 一 個 普 及 性 很 高 。\n",
      "都 著 ， 學 好 你 地 發 展 ， 電 腦 是 一 個 上 ， ， 很 高 。\n",
      "隨 著 科 學 技 術 的 發 展 ， 電 腦 是 一 個 普 及 性 很 高 。\n",
      "({'over_corr': 7, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "我 喜 歡 做 中 國 菜 ， 吃 中 國 菜 ， 還 有 喜 歡 台 灣 得 風 景 ， 每 個 地 方 都 很 美 。\n",
      "我 喜 歡 做 中 國 ， ， 吃 中 國 ， ， 還 有 喜 歡 台 灣 得 ， 的 ， 每 個 地 方 都 很 美 。\n",
      "我 喜 歡 做 中 國 菜 ， 吃 中 國 菜 ， 還 有 喜 歡 台 灣 的 風 景 ， 每 個 地 方 都 很 美 。\n",
      "({'over_corr': 4, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 1 Loss: 4.604251950776496\n",
      "nan {'over_corr': 38967, 'total_err': 5278, 'true_corr': tensor(46, device='cuda:0')} {'over_corr': 3426, 'total_err': 3436, 'true_corr': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:2/10: 100%|██████████| 147/147 [00:09<00:00, 16.11it/s, loss=1.646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "到 了 時 候 ， 他 們 就 開 始 考 食 物 。\n",
      "到 了 時 候 ， 他 們 就 開 始 考 食 物 。\n",
      "到 了 時 候 ， 他 們 就 開 始 烤 食 物 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "我 們 都 知 道 ， 電 腦 及 網 羅 的 發 展 棒 人 類 歷 史 寫 下 了 新 頁 。\n",
      "我 們 都 知 道 ， 電 腦 及 網 那 的 發 展 棒 人 請 辦 中 寫 下 了 新 電 。\n",
      "我 們 都 知 道 ， 電 腦 及 網 絡 的 發 展 幫 人 類 歷 史 寫 下 了 新 頁 。\n",
      "({'over_corr': 4, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "搭 進 第 二 十 一 世 紀 ， 順 著 社 會 、 科 學 的 進 步 ， 網 路 科 學 也 不 斷 地 發 展 同 時 電 腦 領 域 也 速 步 地 更 新 。\n",
      "你 進 第 二 十 一 世 ， ， 難 著 社 會 、 科 學 的 進 步 ， 網 路 科 學 也 不 我 地 發 展 同 時 電 腦 們 不 也 速 步 地 更 新 。\n",
      "踏 進 第 二 十 一 世 紀 ， 順 著 社 會 、 科 學 的 進 步 ， 網 路 科 學 也 不 斷 地 發 展 同 時 電 腦 領 域 也 速 步 地 更 新 。\n",
      "({'over_corr': 5, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 2 Loss: 1.47006278500265\n",
      "nan {'over_corr': 16656, 'total_err': 5278, 'true_corr': tensor(204, device='cuda:0')} {'over_corr': 3095, 'total_err': 3436, 'true_corr': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:3/10: 100%|██████████| 147/147 [00:09<00:00, 16.07it/s, loss=0.484]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "但 問 題 是 假 如 他 上 班 至 下 班 以 來 ， 小 狗 只 好 在 家 一 隻 。\n",
      "但 問 題 是 假 如 他 上 班 至 下 班 以 來 ， 小 狗 只 好 在 家 一 樂 。\n",
      "但 問 題 是 假 如 他 上 班 至 下 班 以 來 ， 小 狗 只 好 在 家 一 直 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "你 去 一 前 ， 我 可 以 給 你 錢 。\n",
      "你 去 一 前 ， 我 可 以 給 你 錢 。\n",
      "你 去 以 前 ， 我 可 以 給 你 錢 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "如 果 您 哪 裡 真 的 有 事 情 不 能 回 來 ． ． ． 還 是 我 這 裡 想 辦 法 先 處 理 吧 ！\n",
      "如 果 您 哪 裡 真 的 有 事 情 不 能 回 來 ． ． ． 還 是 我 這 裡 想 辦 法 先 處 理 吧 ！\n",
      "如 果 您 那 裡 真 的 有 事 情 不 能 回 來 ． ． ． 還 是 我 這 裡 想 辦 法 先 處 理 吧 ！\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 3 Loss: 0.8973802326082372\n",
      "nan {'over_corr': 11612, 'total_err': 5278, 'true_corr': tensor(245, device='cuda:0')} {'over_corr': 2788, 'total_err': 3436, 'true_corr': 19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:4/10: 100%|██████████| 147/147 [00:09<00:00, 15.92it/s, loss=0.698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 的 生 日 那 天 ， 我 沒 有 邀 請 太 多 的 人 。 我 們 可 以 開 心 的 慶 祝 好 之 後 ， 就 一 起 來 規 劃 我 們 的 未 來 。\n",
      "我 的 生 日 那 天 ， 我 沒 有 邀 請 太 多 的 人 。 我 們 可 以 開 心 的 慶 祝 好 之 後 ， 就 一 起 來 規 劃 我 們 的 未 來 。\n",
      "我 的 生 日 那 天 ， 我 沒 有 邀 請 太 多 的 人 。 我 們 可 以 開 心 地 慶 祝 好 之 後 ， 就 一 起 來 規 劃 我 們 的 未 來 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "那 部 很 刺 激 ， 妳 看 過 嗎 。 好 像 叫 「 通 激 犯 」 ， 妳 要 是 沒 看 過 ， 那 天 我 們 一 起 看 看 好 嗎 ？\n",
      "那 部 很 室 上 ， 妳 看 過 嗎 。 好 像 叫 「 通 上 太 」 ， 妳 要 是 沒 看 過 ， 那 天 我 們 一 起 看 看 好 嗎 ？\n",
      "那 部 很 刺 激 ， 妳 看 過 嗎 。 好 像 叫 「 通 緝 犯 」 ， 妳 要 是 沒 看 過 ， 哪 天 我 們 一 起 看 看 好 嗎 ？\n",
      "({'over_corr': 3, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "至 於 這 些 書 和 光 碟 ， 你 可 以 讓 書 局 邦 你 賣 ； 或 者 我 們 會 問 我 們 的 朋 友 誰 可 以 幫 我 們 賣 ， 好 嗎 ！\n",
      "至 於 這 些 書 和 光 有 ， 你 可 以 讓 書 局 興 你 賣 ； 或 者 我 們 會 問 我 們 的 朋 友 誰 可 以 幫 我 們 賣 ， 好 嗎 ！\n",
      "至 於 這 些 書 和 光 碟 ， 你 可 以 讓 書 局 幫 你 賣 ； 或 者 我 們 會 問 我 們 的 朋 友 誰 可 以 幫 我 們 賣 ， 好 嗎 ！\n",
      "({'over_corr': 1, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 4 Loss: 0.6736620780156584\n",
      "nan {'over_corr': 9256, 'total_err': 5278, 'true_corr': tensor(261, device='cuda:0')} {'over_corr': 2545, 'total_err': 3436, 'true_corr': 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:5/10: 100%|██████████| 147/147 [00:09<00:00, 16.04it/s, loss=0.527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "就 算 小 學 常 是 保 護 孩 子 們 的 隱 私 ， 未 來 有 很 大 的 可 能 性 影 片 會 被 偷 或 被 壞 人 用 在 不 好 的 方 面 。\n",
      "就 算 小 學 常 是 保 護 孩 子 們 的 隱 私 ， 未 來 有 很 大 的 可 能 性 影 片 會 被 偷 或 被 壞 人 用 在 不 好 的 方 面 。\n",
      "就 算 小 學 嘗 試 保 護 孩 子 們 的 隱 私 ， 未 來 有 很 大 的 可 能 性 影 片 會 被 偷 或 被 壞 人 用 在 不 好 的 方 面 。\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "您 知 不 知 道 如 果 工 廠 的 聲 音 太 吵 ， 還 要 有 非 常 不 好 的 味 道 ， 臭 臭 的 味 道 讓 他 家 不 能 呼 吸 很 好 的 空 氣 。\n",
      "您 知 不 知 道 如 果 工 廠 的 聲 音 太 吵 ， 還 要 有 非 常 不 好 的 味 道 ， 臭 臭 的 味 道 讓 他 家 不 能 呼 吸 很 好 的 空 氣 。\n",
      "您 知 不 知 道 如 果 工 廠 的 聲 音 太 吵 ， 還 要 有 非 常 不 好 的 味 道 ， 臭 臭 的 味 道 讓 大 家 不 能 呼 吸 很 好 的 空 氣 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "如 果 在 教 室 裡 有 一 個 問 題 ， 我 們 家 常 會 這 道 為 甚 麼 會 發 生 這 件 事 而 這 道 誰 對 誰 做 錯 。\n",
      "如 果 在 教 室 裡 有 一 個 問 題 ， 我 們 家 常 會 這 道 為 甚 麼 會 發 生 這 件 事 而 這 道 誰 對 誰 做 錯 。\n",
      "如 果 在 教 室 裡 有 一 個 問 題 ， 我 們 家 長 會 知 道 為 甚 麼 會 發 生 這 件 事 而 這 道 誰 對 誰 做 錯 。\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 5 Loss: 0.5516086354547617\n",
      "nan {'over_corr': 7670, 'total_err': 5278, 'true_corr': tensor(255, device='cuda:0')} {'over_corr': 2334, 'total_err': 3436, 'true_corr': 37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:6/10: 100%|██████████| 147/147 [00:09<00:00, 16.04it/s, loss=0.825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "問 題 就 是 「 半 工 半 讀 」 又 兩 片 影 像 ， 又 好 處 並 也 存 在 壞 處 。\n",
      "問 題 就 是 「 半 工 半 讀 」 又 兩 片 影 像 ， 又 好 處 並 也 存 在 壞 處 。\n",
      "問 題 就 是 「 半 工 半 讀 」 有 兩 邊 影 響 ， 有 好 處 並 也 存 在 壞 處 。\n",
      "({'over_corr': 0, 'total_err': 4, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "我 不 咀 導 要 是 買 聘 果 西 瓜 李 子 。\n",
      "我 不 放 導 要 是 買 一 果 西 什 李 子 。\n",
      "我 不 知 道 要 是 買 蘋 果 西 瓜 李 子 。\n",
      "({'over_corr': 1, 'total_err': 3, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "放 完 家 就 回 來 忙 碌 的 單 身 貴 族 。 從 我 的 心 願 和 想 法 來 看 ， 我 想 很 多 人 也 會 同 情 ， 而 且 喜 歡 上 這 個 的 興 行 業 。\n",
      "放 完 家 就 回 來 忙 碌 的 單 身 貴 課 。 從 我 的 心 願 和 想 法 來 看 ， 我 想 很 多 人 也 會 同 情 ， 而 且 喜 歡 上 這 個 的 興 行 業 。\n",
      "放 完 假 就 回 來 忙 碌 的 單 身 貴 族 。 從 我 的 心 願 和 想 法 來 看 ， 我 想 很 多 人 也 會 同 情 ， 而 且 喜 歡 上 這 個 的 新 行 業 。\n",
      "({'over_corr': 1, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 6 Loss: 0.47369695480178003\n",
      "nan {'over_corr': 6348, 'total_err': 5278, 'true_corr': tensor(275, device='cuda:0')} {'over_corr': 2119, 'total_err': 3436, 'true_corr': 45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:7/10: 100%|██████████| 147/147 [00:09<00:00, 16.07it/s, loss=0.333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今 天 大 明 第 一 次 到 十 大 去 ， 他 是 新 生 在 師 大 。\n",
      "今 天 大 明 第 一 次 到 十 大 去 ， 他 是 新 生 在 師 大 。\n",
      "今 天 大 明 第 一 次 到 師 大 去 ， 他 是 新 生 在 師 大 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "王 先 生 跟 他 說 好 多 話 ， 他 們 一 直 說 話 一 直 笑 很 開 興 了 ！\n",
      "王 先 生 跟 他 說 好 多 話 ， 他 們 一 直 說 話 一 直 笑 很 開 興 了 ！\n",
      "王 先 生 跟 他 說 好 多 話 ， 他 們 一 直 說 話 一 直 笑 很 開 心 了 ！\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "而 且 她 不 止 對 做 貿 易 很 專 業 ， 她 還 常 常 去 國 外 跟 各 種 各 樣 的 公 司 做 生 意 。\n",
      "而 且 她 不 止 對 做 天 易 很 專 業 ， 她 還 常 常 去 國 外 跟 各 種 各 樣 的 公 司 做 生 意 。\n",
      "而 且 她 不 只 對 做 貿 易 很 專 業 ， 她 還 常 常 去 國 外 跟 各 種 各 樣 的 公 司 做 生 意 。\n",
      "({'over_corr': 1, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 7 Loss: 0.4160800231557314\n",
      "nan {'over_corr': 5512, 'total_err': 5278, 'true_corr': tensor(281, device='cuda:0')} {'over_corr': 2001, 'total_err': 3436, 'true_corr': 54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:8/10: 100%|██████████| 147/147 [00:09<00:00, 16.05it/s, loss=0.248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "想 說 白 天 大 家 都 上 班 ， 多 少 能 必 開 這 些 困 擾 但 晚 上 回 來 ， 原 本 可 以 好 好 休 息 、 放 鬆 自 己 ， 小 孩 也 能 好 好 做 功 課 ， 但 您 工 廠 又 進 行 加 班 。\n",
      "想 說 白 天 大 家 都 上 班 ， 多 少 能 必 開 這 些 困 擾 但 晚 上 回 來 ， 原 本 可 以 好 好 休 息 、 放 鬆 自 己 ， 小 孩 也 能 好 好 做 功 課 ， 但 您 工 廠 又 進 行 加 班 。\n",
      "想 說 白 天 大 家 都 上 班 ， 多 少 能 避 開 這 些 困 擾 但 晚 上 回 來 ， 原 本 可 以 好 好 休 息 、 放 鬆 自 己 ， 小 孩 也 能 好 好 做 功 課 ， 但 您 工 廠 又 進 行 加 班 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "因 為 時 間 的 關 係 ， 都 極 少 和 家 人 相 處 ， 就 趁 著 這 個 機 會 順 道 和 家 人 好 好 的 去 玩 玩 ， 放 鬆 一 下 心 情 ， 這 何 嘗 不 是 件 好 事 呢 。\n",
      "因 為 時 間 的 關 係 ， 都 極 少 和 家 人 相 處 ， 就 趁 著 這 個 機 會 順 道 和 家 人 好 好 的 去 玩 玩 ， 放 鬆 一 下 心 情 ， 這 何 居 不 是 件 好 事 呢 。\n",
      "因 為 時 間 的 關 係 ， 都 極 少 和 家 人 相 處 ， 就 趁 著 這 個 機 會 順 道 和 家 人 好 好 地 去 玩 玩 ， 放 鬆 一 下 心 情 ， 這 何 嘗 不 是 件 好 事 呢 。\n",
      "({'over_corr': 1, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "老 師 說 ： 「 好 好 美 關 係 ， 明 天 你 得 來 ８ 點 好 不 。 」 。\n",
      "老 師 說 ： 「 好 好 美 關 係 ， 明 天 你 得 來 ８ 點 好 不 。 」 。\n",
      "老 師 說 ： 「 好 好 沒 關 係 ， 明 天 你 得 來 ８ 點 好 不 。 」 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 8 Loss: 0.37260499302627276\n",
      "nan {'over_corr': 5327, 'total_err': 5278, 'true_corr': tensor(252, device='cuda:0')} {'over_corr': 1997, 'total_err': 3436, 'true_corr': 49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:9/10: 100%|██████████| 147/147 [00:09<00:00, 16.08it/s, loss=0.255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "「 家 張 限 制 青 少 年 上 網 時 數 」 的 話 題 ？ 我 非 常 支 持 ！\n",
      "「 家 張 限 制 青 少 年 上 網 時 數 」 的 話 題 ？ 我 非 常 支 持 ！\n",
      "「 家 長 限 制 青 少 年 上 網 時 數 」 的 話 題 ？ 我 非 常 支 持 ！\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "孩 子 先 在 也 要 上 高 中 了 吧 ， 你 還 可 以 輔 導 他 的 學 習 。\n",
      "孩 子 先 在 也 要 上 高 中 了 吧 ， 你 還 可 以 輔 導 他 的 學 習 。\n",
      "孩 子 現 在 也 要 上 高 中 了 吧 ， 你 還 可 以 輔 導 他 的 學 習 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "他 們 只 能 有 兩 個 選 擇 ： 接 受 降 新 或 自 動 離 職 。\n",
      "他 們 只 能 有 兩 個 選 擇 ： 接 受 降 新 或 自 動 離 職 。\n",
      "他 們 只 能 有 兩 個 選 擇 ： 接 受 降 薪 或 自 動 離 職 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 9 Loss: 0.33716014686490403\n",
      "nan {'over_corr': 5352, 'total_err': 5278, 'true_corr': tensor(378, device='cuda:0')} {'over_corr': 2016, 'total_err': 3436, 'true_corr': 80}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:10/10: 100%|██████████| 147/147 [00:09<00:00, 16.02it/s, loss=0.254]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "這 樣 就 可 以 放 便 多 了 。 以 我 個 性 不 想 麻 煩 又 喜 歡 動 物 的 人 ， 這 重 設 備 是 滿 不 錯 的 。\n",
      "這 樣 就 可 以 放 便 多 了 。 以 我 個 性 不 想 麻 煩 又 喜 歡 動 物 的 人 ， 這 重 設 備 是 滿 不 錯 的 。\n",
      "這 樣 就 可 以 方 便 多 了 。 以 我 個 性 不 想 麻 煩 又 喜 歡 動 物 的 人 ， 這 種 設 備 是 滿 不 錯 的 。\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "因 為 天 氣 很 好 ， 所 以 他 打 算 去 錄 行 。\n",
      "因 為 天 氣 很 好 ， 所 以 他 打 算 去 錄 行 。\n",
      "因 為 天 氣 很 好 ， 所 以 他 打 算 去 旅 行 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "不 上 課 的 時 候 ， 我 常 常 跟 朋 友 去 玩 玩 ， 看 一 看 在 台 北 好 看 的 地 方 ， 晚 上 我 就 看 書 跟 學 子 。\n",
      "不 上 課 的 時 候 ， 我 常 常 跟 朋 友 去 玩 玩 ， 看 一 看 在 台 北 好 看 的 地 方 ， 晚 上 我 就 看 書 跟 學 子 。\n",
      "不 上 課 的 時 候 ， 我 常 常 跟 朋 友 去 玩 玩 ， 看 一 看 在 台 北 好 看 的 地 方 ， 晚 上 我 就 看 書 跟 學 字 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 10 Loss: 0.3092169188926009\n",
      "nan {'over_corr': 4738, 'total_err': 5278, 'true_corr': tensor(314, device='cuda:0')} {'over_corr': 1840, 'total_err': 3436, 'true_corr': 75}\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "from models import Seq2SeqModel\n",
    "from torch.nn.functional import cross_entropy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# temp_data\n",
    "nhead = 4  # 多头注意力机制的头数\n",
    "num_decoder_layers = 2\n",
    "dim_feedforward = 3072\n",
    "max_seq_len = 128\n",
    "dropout = 0.1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tokenizer = BertTokenizer.from_pretrained(checkpoint)\n",
    "    bert = BertModel.from_pretrained(checkpoint)\n",
    "\n",
    "    train_dataset = CSCDataset([SIGHAN_train_dir_err, SIGHAN_train_dir_corr], tokenizer)\n",
    "    train_data_loader = DataLoader(\n",
    "        train_dataset, num_workers=0, shuffle=True, batch_size=16\n",
    "    )\n",
    "\n",
    "    test_dataset = CSCDataset(\n",
    "        [SIGHAN_train_dir_err14, SIGHAN_train_dir_corr14], tokenizer\n",
    "    )\n",
    "    test_data_loader = DataLoader(\n",
    "        test_dataset, num_workers=0, shuffle=True, batch_size=32\n",
    "    )\n",
    "\n",
    "    model = Seq2SeqModel(\n",
    "        bert, nhead, num_decoder_layers, dim_feedforward, max_seq_len, dropout\n",
    "    )\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(\n",
    "            enumerate(train_data_loader),\n",
    "            desc=f\"Epoch:{epoch+1}/{epochs}\",\n",
    "            total=len(train_data_loader),\n",
    "        )\n",
    "\n",
    "        for i, batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device).type(torch.float)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, src_mask=attention_mask)\n",
    "            logits = outputs.permute(0, 2, 1)  # (batch_size, vocab_size, seq_len)\n",
    "\n",
    "            # 反向传播在这，故labels不需要传入模型\n",
    "            loss = cross_entropy(logits, labels, ignore_index=tokenizer.pad_token_id)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            progress_bar.set_postfix({\"loss\": \"{:.3f}\".format(loss.item())})\n",
    "\n",
    "        t = torch.argmax(outputs, dim=-1)\n",
    "        nt = t * attention_mask\n",
    "        pred = tokenizer.batch_decode(nt, skip_special_tokens=True)\n",
    "        # print(pred)\n",
    "        # print(f\"origin{tokenizer.batch_decode(labels, skip_special_tokens=True)}\")\n",
    "\n",
    "        for i, v in enumerate(nt):\n",
    "            r, l = input_ids[i], labels[i]\n",
    "            print(tokenizer.decode(r, skip_special_tokens=True))\n",
    "            print(tokenizer.decode(v, skip_special_tokens=True))\n",
    "            print(tokenizer.decode(l, skip_special_tokens=True))\n",
    "            print(cal_err(r, v, l))\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss / len(train_data_loader)}\")\n",
    "        test(model, tokenizer, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f485237-bafa-452c-b127-2a2daeb44b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1/10: 100%|██████████| 147/147 [00:09<00:00, 16.11it/s, loss=0.330]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如 果 他 真 的 不 再 需 要 這 些 ， 他 起 碼 應 該 感 謝 你 ， 而 且 要 換 給 你 錢 。\n",
      "如 果 他 真 的 不 再 需 要 這 些 ， 他 起 嗎 應 該 感 謝 你 ， 而 且 要 換 給 你 錢 。\n",
      "如 果 他 真 的 不 再 需 要 這 些 ， 他 起 碼 應 該 感 謝 你 ， 而 且 要 還 給 你 錢 。\n",
      "({'over_corr': 1, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "作 天 我 看 到 你 太 太 ， 她 告 訴 你 有 感 冒 。\n",
      "作 天 我 看 到 你 太 太 ， 她 告 訴 你 有 感 冒 。\n",
      "昨 天 我 看 到 你 太 太 ， 她 告 訴 你 有 感 冒 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "因 為 大 的 家 裡 學 校 很 遠 ， 所 以 他 要 早 一 點 起 來 。\n",
      "因 為 大 的 家 裡 學 校 很 遠 ， 所 以 他 要 早 一 點 起 來 。\n",
      "因 為 他 的 家 離 學 校 很 遠 ， 所 以 他 要 早 一 點 起 來 。\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 1 Loss: 0.2860999033361876\n",
      "nan {'over_corr': 5122, 'total_err': 5278, 'true_corr': tensor(343, device='cuda:0')} {'over_corr': 1956, 'total_err': 3436, 'true_corr': 76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:2/10: 100%|██████████| 147/147 [00:09<00:00, 16.11it/s, loss=0.304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你 看 ， 你 的 情 況 不 是 那 嗎 誇 張 。\n",
      "你 看 ， 你 的 情 況 不 是 那 嗎 誇 張 。\n",
      "你 看 ， 你 的 情 況 不 是 那 麼 誇 張 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "第 四 個 象 片 兒 ： 兩 個 人 都 看 點 影 。\n",
      "第 四 個 相 片 兒 ： 兩 個 人 都 看 點 影 。\n",
      "第 四 個 相 片 兒 ： 兩 個 人 都 看 電 影 。\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(1, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "接 者 因 為 民 眾 晚 上 十 點 之 後 希 望 能 夠 有 安 靜 既 舒 適 的 睡 眠 時 間 ， 本 人 也 得 知 貴 工 廠 是 裁 二 十 四 小 時 輪 班 運 作 方 式 ， 你 們 在 這 裡 開 工 廠 已 經 有 很 長 的 一 段 時 間 。\n",
      "接 者 因 為 民 眾 晚 上 十 點 之 後 希 望 能 夠 有 安 靜 既 舒 適 的 睡 眠 時 間 ， 本 人 也 得 知 貴 工 廠 是 裁 二 十 四 小 時 輪 班 運 作 方 式 ， 你 們 在 這 裡 開 工 廠 已 經 有 很 長 的 一 段 時 間 。\n",
      "接 著 因 為 民 眾 晚 上 十 點 之 後 希 望 能 夠 有 安 靜 及 舒 適 的 睡 眠 時 間 ， 本 人 也 得 知 貴 工 廠 是 採 二 十 四 小 時 輪 班 運 作 方 式 ， 你 們 在 這 裡 開 工 廠 已 經 有 很 長 的 一 段 時 間 。\n",
      "({'over_corr': 0, 'total_err': 3, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 2 Loss: 0.2648044910763397\n",
      "nan {'over_corr': 5504, 'total_err': 5278, 'true_corr': tensor(384, device='cuda:0')} {'over_corr': 2100, 'total_err': 3436, 'true_corr': 73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:3/10: 100%|██████████| 147/147 [00:09<00:00, 16.07it/s, loss=0.256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "下 禮 拜 五 下 午 十 二 點 十 分 在 學 校 大 們 口 見 面 ！\n",
      "下 禮 拜 五 下 午 十 二 點 十 分 在 學 校 大 們 口 見 面 ！\n",
      "下 禮 拜 五 下 午 十 二 點 十 分 在 學 校 大 門 口 見 面 ！\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "我 有 很 多 領 據 工 作 在 李 工 廠 ， 這 家 工 廠 幫 這 個 城 市 的 經 濟 。\n",
      "我 有 很 多 領 據 工 作 在 李 工 廠 ， 這 家 工 廠 幫 這 個 城 市 的 經 濟 。\n",
      "我 有 很 多 鄰 居 工 作 在 李 工 廠 ， 這 家 工 廠 幫 這 個 城 市 的 經 濟 。\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "比 方 說 ： 老 師 教 學 生 的 時 候 要 用 什 麼 辦 法 其 實 是 老 師 的 人 權 ， 那 選 是 他 們 的 最 基 本 的 人 權 。\n",
      "比 方 說 ： 老 師 教 學 生 的 時 候 要 用 什 麼 辦 法 其 實 是 老 師 的 人 權 ， 那 選 是 他 們 的 最 基 本 的 人 權 。\n",
      "比 方 說 ： 老 師 教 學 生 的 時 候 要 用 什 麼 辦 法 其 實 是 老 師 的 人 權 ， 那 些 是 他 們 的 最 基 本 的 人 權 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 3 Loss: 0.24479774421169645\n",
      "nan {'over_corr': 5689, 'total_err': 5278, 'true_corr': tensor(410, device='cuda:0')} {'over_corr': 2098, 'total_err': 3436, 'true_corr': 83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:4/10: 100%|██████████| 147/147 [00:09<00:00, 16.08it/s, loss=0.183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 們 急 忙 的 前 往 馬 偕 醫 院 急 診 室 就 診 ， 醫 師 診 斷 為 ＂ 進 食 農 藥 導 致 食 物 中 毒 ＂ 。\n",
      "我 們 急 忙 的 前 往 馬 偕 醫 院 急 診 室 就 診 ， 醫 師 診 斷 為 ＂ 進 食 農 藥 導 致 食 物 中 毒 ＂ 。\n",
      "我 們 急 忙 地 前 往 馬 偕 醫 院 急 診 室 就 診 ， 醫 師 診 斷 為 ＂ 進 食 農 藥 導 致 食 物 中 毒 ＂ 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "如 果 你 又 要 去 的 話 ， 你 在 跟 我 聯 絡 。\n",
      "如 果 你 有 要 去 的 話 ， 你 在 跟 我 聯 絡 。\n",
      "如 果 你 有 要 去 的 話 ， 你 再 跟 我 聯 絡 。\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(1, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "那 樣 ， 你 就 不 但 能 夠 享 受 你 喜 歡 的 工 作 ， 也 可 以 鑽 到 比 較 多 薪 水 ， 支 持 你 的 家 庭 。\n",
      "那 樣 ， 你 就 不 但 能 夠 享 受 你 喜 歡 的 工 作 ， 也 可 以 賺 到 比 較 多 薪 水 ， 支 持 你 的 家 庭 。\n",
      "那 樣 ， 你 就 不 但 能 夠 享 受 你 喜 歡 的 工 作 ， 也 可 以 賺 到 比 較 多 薪 水 ， 支 持 你 的 家 庭 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(1, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 1})\n",
      "Epoch 4 Loss: 0.2279649613057675\n",
      "nan {'over_corr': 6384, 'total_err': 5278, 'true_corr': tensor(416, device='cuda:0')} {'over_corr': 2254, 'total_err': 3436, 'true_corr': 84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:5/10: 100%|██████████| 147/147 [00:09<00:00, 16.09it/s, loss=0.238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "英 國 的 批 具 很 好 喝 ， 我 很 喜 歡 ！\n",
      "英 國 的 批 具 很 好 喝 ， 我 很 喜 歡 ！\n",
      "英 國 的 啤 酒 很 好 喝 ， 我 很 喜 歡 ！\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "我 是 家 庭 主 婦 ， 育 有 三 個 孩 子 ， 先 生 在 中 華 電 信 擔 任 課 服 人 員 。\n",
      "我 是 家 庭 主 婦 ， 育 有 三 個 孩 子 ， 先 生 在 中 華 電 信 擔 任 課 服 人 員 。\n",
      "我 是 家 庭 主 婦 ， 育 有 三 個 孩 子 ， 先 生 在 中 華 電 信 擔 任 客 服 人 員 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "如 果 我 們 烤 爐 用 網 路 來 交 朋 友 的 原 因 ， 我 們 就 看 出 為 甚 麼 那 麼 多 人 喜 歡 這 個 選 擇 。\n",
      "如 果 我 們 烤 慮 用 網 路 來 交 朋 友 的 原 因 ， 我 們 就 看 出 為 甚 麼 那 麼 多 人 喜 歡 這 個 選 擇 。\n",
      "如 果 我 們 考 慮 用 網 路 來 交 朋 友 的 原 因 ， 我 們 就 看 出 為 甚 麼 那 麼 多 人 喜 歡 這 個 選 擇 。\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(1, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 5 Loss: 0.21146829791215002\n",
      "nan {'over_corr': 7441, 'total_err': 5278, 'true_corr': tensor(482, device='cuda:0')} {'over_corr': 2424, 'total_err': 3436, 'true_corr': 75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:6/10: 100%|██████████| 147/147 [00:09<00:00, 16.03it/s, loss=0.256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有 的 表 現 不 好 的 孩 子 而 且 是 有 很 嚴 格 的 父 母 ， 他 們 回 家 時 一 定 是 被 捏 或 被 打 一 頓 ， 這 樣 他 們 可 台 可 憐 了 。\n",
      "有 的 表 現 不 好 的 孩 子 而 且 是 有 很 嚴 格 的 父 母 ， 他 們 回 家 時 一 定 是 被 捏 或 被 打 一 頓 ， 這 樣 他 們 可 台 可 憐 了 。\n",
      "有 的 表 現 不 好 的 孩 子 而 且 是 有 很 嚴 格 的 父 母 ， 他 們 回 家 時 一 定 是 被 捏 或 被 打 一 頓 ， 這 樣 他 們 可 太 可 憐 了 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "各 國 都 市 化 的 勢 趨 很 強 烈 ， 炫 麗 多 採 的 大 城 市 是 國 家 繁 榮 的 象 徵 。\n",
      "各 國 都 市 化 的 勢 趨 很 強 烈 ， 炫 麗 多 採 的 大 城 市 是 國 家 繁 榮 的 象 徵 。\n",
      "各 國 都 市 化 的 勢 趨 很 強 烈 ， 炫 麗 多 彩 的 大 城 市 是 國 家 繁 榮 的 象 徵 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "那 到 底 保 護 環 境 比 建 立 公 路 尤 甚 麼 更 多 的 利 處 呢 ？\n",
      "那 到 底 保 護 環 境 比 建 立 公 路 尤 甚 麼 更 多 的 利 處 呢 ？\n",
      "那 到 底 保 護 環 境 比 建 立 公 路 有 甚 麼 更 多 的 利 處 呢 ？\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 6 Loss: 0.1961256876385131\n",
      "nan {'over_corr': 8266, 'total_err': 5278, 'true_corr': tensor(490, device='cuda:0')} {'over_corr': 2553, 'total_err': 3436, 'true_corr': 72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:7/10: 100%|██████████| 147/147 [00:09<00:00, 16.09it/s, loss=0.245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 的 公 司 有 兩 名 員 工 也 被 裁 員 了 ， 因 此 他 們 打 算 要 一 起 創 業 當 老 闆 ， 還 邀 請 我 來 參 加 開 募 呢 。\n",
      "我 的 公 司 有 兩 名 員 工 也 被 裁 員 了 ， 因 此 他 們 打 算 要 一 起 創 業 當 老 闆 ， 還 邀 請 我 來 參 加 開 幕 呢 。\n",
      "我 的 公 司 有 兩 名 員 工 也 被 裁 員 了 ， 因 此 他 們 打 算 要 一 起 創 業 當 老 闆 ， 還 邀 請 我 來 參 加 開 幕 呢 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(1, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 1})\n",
      "隨 之 社 會 的 進 步 及 競 爭 ， 還 有 物 價 不 斷 的 攀 升 導 致 生 活 更 有 挑 戰 。\n",
      "隨 之 社 會 的 進 步 及 競 爭 ， 還 有 物 價 不 斷 的 攀 升 導 致 生 活 更 有 挑 戰 。\n",
      "隨 著 社 會 的 進 步 及 競 爭 ， 還 有 物 價 不 斷 地 攀 升 導 致 生 活 更 有 挑 戰 。\n",
      "({'over_corr': 0, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "我 們 真 希 望 貴 工 廠 能 接 受 我 們 的 意 見 ， 我 們 理 會 代 表 下 禮 拜 一 會 訪 問 您 ， 那 時 候 請 給 我 們 聽 聽 您 們 的 看 法 好 嗎 ？\n",
      "我 們 真 希 望 貴 工 廠 能 接 受 我 們 的 意 見 ， 我 們 理 會 代 表 下 禮 拜 一 會 訪 問 您 ， 那 時 候 請 給 我 們 聽 聽 您 們 的 看 法 好 嗎 ？\n",
      "我 們 真 希 望 貴 工 廠 能 接 受 我 們 的 意 見 ， 我 們 里 會 代 表 下 禮 拜 一 會 訪 問 您 ， 那 時 候 請 給 我 們 聽 聽 您 們 的 看 法 好 嗎 ？\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 7 Loss: 0.1818399307679157\n",
      "nan {'over_corr': 13046, 'total_err': 5278, 'true_corr': tensor(481, device='cuda:0')} {'over_corr': 2998, 'total_err': 3436, 'true_corr': 40}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:8/10: 100%|██████████| 147/147 [00:09<00:00, 16.06it/s, loss=0.229]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "上 課 時 總 不 能 專 心 ， 因 為 會 覺 得 有 很 多 眼 睛 在 登 著 我 。\n",
      "上 課 時 總 不 能 專 心 ， 因 為 會 覺 得 有 很 多 眼 睛 在 登 著 我 。\n",
      "上 課 時 總 不 能 專 心 ， 因 為 會 覺 得 有 很 多 眼 睛 在 瞪 著 我 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "因 為 我 好 想 證 明 自 己 ， 所 以 拼 命 去 找 很 大 的 交 易 機 會 ， 結 果 檢 了 合 同 後 ， 才 發 現 自 己 被 騙 ， 總 價 值 和 痛 快 到 新 台 幣 五 億 元 。\n",
      "因 為 我 好 想 證 明 自 己 ， 所 以 拼 命 去 找 很 大 的 交 易 機 會 ， 結 果 檢 了 合 同 後 ， 才 發 現 自 己 被 騙 ， 總 價 值 和 痛 快 到 新 台 幣 五 億 元 。\n",
      "因 為 我 好 想 證 明 自 己 ， 所 以 拼 命 去 找 很 大 的 交 易 機 會 ， 結 果 簽 了 合 同 後 ， 才 發 現 自 己 被 騙 ， 總 價 值 合 同 快 到 新 台 幣 五 億 元 。\n",
      "({'over_corr': 0, 'total_err': 3, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "我 從 小 一 直 看 著 你 經 營 公 司 的 樣 子 。 所 以 知 道 經 營 公 司 真 的 不 簡 單 ， 很 幸 苦 。\n",
      "我 從 小 一 直 看 著 你 經 營 公 司 的 樣 子 。 所 以 知 道 經 營 公 司 真 的 不 簡 單 ， 很 幸 苦 。\n",
      "我 從 小 一 直 看 著 你 經 營 公 司 的 樣 子 。 所 以 知 道 經 營 公 司 真 的 不 簡 單 ， 很 辛 苦 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 8 Loss: 0.16719788145654055\n",
      "nan {'over_corr': 17708, 'total_err': 5278, 'true_corr': tensor(485, device='cuda:0')} {'over_corr': 3210, 'total_err': 3436, 'true_corr': 22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:9/10: 100%|██████████| 147/147 [00:09<00:00, 16.09it/s, loss=0.108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "這 樣 對 小 孩 子 的 安 全 好 ， 還 會 讓 父 母 請 放 心 。\n",
      "這 樣 對 小 孩 子 的 安 全 好 ， 還 會 讓 父 母 請 放 心 。\n",
      "這 樣 對 小 孩 子 的 安 全 好 ， 還 會 讓 父 母 親 放 心 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "因 為 又 大 聲 音 又 臭 味 ， 所 以 我 們 不 知 道 什 麼 告 訴 你 我 們 的 問 題 。\n",
      "因 為 又 大 聲 音 又 臭 味 ， 所 以 我 們 不 知 道 什 麼 告 訴 你 我 們 的 問 題 。\n",
      "因 為 又 大 聲 音 又 臭 味 ， 所 以 我 們 不 知 道 怎 麼 告 訴 你 我 們 的 問 題 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "老 闆 告 訴 王 大 華 幫 你 點 蔡 。\n",
      "老 闆 告 訴 王 大 華 幫 你 點 菜 。\n",
      "老 闆 告 訴 王 大 華 幫 你 點 菜 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(1, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 1})\n",
      "Epoch 9 Loss: 0.15367259951878567\n",
      "nan {'over_corr': 19377, 'total_err': 5278, 'true_corr': tensor(529, device='cuda:0')} {'over_corr': 3259, 'total_err': 3436, 'true_corr': 19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:10/10: 100%|██████████| 147/147 [00:09<00:00, 16.03it/s, loss=0.104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "因 為 德 國 的 天 氣 不 是 這 麼 熱 的 ， 也 不 太 施 。\n",
      "因 為 德 國 的 天 氣 不 是 這 麼 熱 的 ， 也 不 太 施 。\n",
      "因 為 德 國 的 天 氣 不 是 這 麼 熱 的 ， 也 不 太 濕 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "雖 然 對 我 來 說 太 大 而 不 是 很 方 便 ， 但 總 比 冷 死 好 。 就 這 樣 那 個 棉 被 默 默 的 用 到 現 在 了 。\n",
      "雖 然 對 我 來 說 太 大 而 不 是 很 方 便 ， 但 總 比 冷 死 好 。 就 這 樣 那 個 棉 被 默 默 的 用 到 現 在 了 。\n",
      "雖 然 對 我 來 說 太 大 而 不 是 很 方 便 ， 但 總 比 冷 死 好 。 就 這 樣 那 個 棉 被 默 默 地 用 到 現 在 了 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 0})\n",
      "所 以 我 覺 得 除 非 接 受 安 寧 療 護 的 病 人 為 了 跟 寵 物 一 起 過 好 好 地 過 余 生 ， 也 可 以 利 用 這 種 寵 物 出 租 公 司 。\n",
      "所 以 我 覺 得 除 非 接 受 安 寧 療 護 的 病 人 為 了 跟 寵 物 一 起 過 好 好 地 過 餘 生 ， 也 可 以 利 用 這 種 寵 物 出 租 公 司 。\n",
      "所 以 我 覺 得 除 非 接 受 安 寧 療 護 的 病 人 為 了 跟 寵 物 一 起 過 好 好 地 過 餘 生 ， 也 可 以 利 用 這 種 寵 物 出 租 公 司 。\n",
      "({'over_corr': 0, 'total_err': 1, 'true_corr': tensor(1, device='cuda:0')}, {'over_corr': 0, 'total_err': 1, 'true_corr': 1})\n",
      "Epoch 10 Loss: 0.14103904898677552\n",
      "nan {'over_corr': 23673, 'total_err': 5278, 'true_corr': tensor(509, device='cuda:0')} {'over_corr': 3327, 'total_err': 3436, 'true_corr': 9}\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(\n",
    "        enumerate(train_data_loader),\n",
    "        desc=f\"Epoch:{epoch+1}/{epochs}\",\n",
    "        total=len(train_data_loader),\n",
    "    )\n",
    "\n",
    "    for i, batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device).type(torch.float)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, src_mask=attention_mask)\n",
    "        logits = outputs.permute(0, 2, 1)  # (batch_size, vocab_size, seq_len)\n",
    "\n",
    "        # 反向传播在这，故labels不需要传入模型\n",
    "        loss = cross_entropy(logits, labels, ignore_index=tokenizer.pad_token_id)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        progress_bar.set_postfix({\"loss\": \"{:.3f}\".format(loss.item())})\n",
    "\n",
    "    t = torch.argmax(outputs, dim=-1)\n",
    "    nt = t * attention_mask\n",
    "    pred = tokenizer.batch_decode(nt, skip_special_tokens=True)\n",
    "    # print(pred)\n",
    "    # print(f\"origin{tokenizer.batch_decode(labels, skip_special_tokens=True)}\")\n",
    "\n",
    "    for i, v in enumerate(nt):\n",
    "        r, l = input_ids[i], labels[i]\n",
    "        print(tokenizer.decode(r, skip_special_tokens=True))\n",
    "        print(tokenizer.decode(v, skip_special_tokens=True))\n",
    "        print(tokenizer.decode(l, skip_special_tokens=True))\n",
    "        print(cal_err(r, v, l))\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss / len(train_data_loader)}\")\n",
    "    test(model, tokenizer, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ba8cd-90c9-491a-88c6-aab71560aa40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "090f1b7d-394d-4510-b425-901f72548d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.matrices = [\"over_corr\", \"total_err\", \"true_corr\"]\n",
    "\n",
    "    def train(self, dataloader, epoch):\n",
    "        self.iteration(dataloader, epoch)\n",
    "\n",
    "    def test(self, dataloader):\n",
    "        self.iteration(dataloader, train=False)\n",
    "\n",
    "    def iteration(self, dataloader, epochs=1, train=True):\n",
    "        mode = \"train\" if train else \"dev\"\n",
    "        model.train() if train else model.eval()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # matrices\n",
    "            total_loss = 0\n",
    "            char_level = {key: 0 for key in self.matrices}\n",
    "            sent_level = {key: 0 for key in self.matrices}\n",
    "\n",
    "            progress_bar = tqdm(\n",
    "                dataloader,\n",
    "                desc=f\"{mode} Epoch:{epoch+1}/{epochs}\",\n",
    "                total=len(dataloader),\n",
    "            )\n",
    "            for batch in progress_bar:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "\n",
    "                outputs = model(input_ids, src_mask=attention_mask, tgt=labels)\n",
    "                logits = outputs.permute(0, 2, 1)  # (batch_size, vocab_size, seq_len)\n",
    "\n",
    "                loss = cross_entropy(\n",
    "                    logits, labels, ignore_index=tokenizer.pad_token_id\n",
    "                )\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                progress_bar.set_postfix({\"loss\": \"{:.3f}\".format(loss.item())})\n",
    "\n",
    "    def cal_err(raw_sentence, pred_sentence, corr_sentence):\n",
    "        char_level = {key: 0 for key in self.matrices}\n",
    "        sent_level = {key: 0 for key in self.matrices}\n",
    "\n",
    "        for i, c in enumerate(raw_sentence):\n",
    "            pc, cc = pred_sentence[i], corr_sentence[i]\n",
    "            f1 = f2 = False\n",
    "\n",
    "            if cc != c:\n",
    "                char_level[\"total_err\"] += 1\n",
    "                char_level[\"true_corr\"] += pc == cc\n",
    "                f1 = True\n",
    "            elif pc != cc:\n",
    "                char_level[\"over_corr\"] += 1\n",
    "                f2 = True\n",
    "\n",
    "        # true_corr 未计算\n",
    "        sent_level[\"total_err\"] += f1\n",
    "        sent_level[\"over_corr\"] += f2\n",
    "\n",
    "        return char_level, sent_level"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc_env",
   "language": "python",
   "name": "csc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
