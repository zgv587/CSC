{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6508b6d6-a22b-4dba-ba9b-805cfa20a99a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T08:00:29.127314Z",
     "iopub.status.busy": "2024-12-09T08:00:29.127314Z",
     "iopub.status.idle": "2024-12-09T08:01:06.905027Z",
     "shell.execute_reply": "2024-12-09T08:01:06.905027Z",
     "shell.execute_reply.started": "2024-12-09T08:00:29.127314Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# Implemented by myself\n",
    "from config import *\n",
    "from data_processer import CSCDataset\n",
    "from models import CombineBertModel, DecoderLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74c9c49d-ca57-4b70-8333-624dcc395a9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T08:01:06.906035Z",
     "iopub.status.busy": "2024-12-09T08:01:06.906035Z",
     "iopub.status.idle": "2024-12-09T08:01:06.911342Z",
     "shell.execute_reply": "2024-12-09T08:01:06.911342Z",
     "shell.execute_reply.started": "2024-12-09T08:01:06.906035Z"
    }
   },
   "outputs": [],
   "source": [
    "def cal_err(raw_sentence, pred_sentence, corr_sentence):\n",
    "    matrices = [\"over_corr\", \"total_err\", \"true_corr\"]\n",
    "    char_level = {key: 0 for key in matrices}\n",
    "    sent_level = {key: 0 for key in matrices}\n",
    "\n",
    "    f1 = f2 = 0\n",
    "    for i, c in enumerate(raw_sentence):\n",
    "        pc, cc = pred_sentence[i], corr_sentence[i]\n",
    "\n",
    "        if cc != c:\n",
    "            char_level[\"total_err\"] += 1\n",
    "            char_level[\"true_corr\"] += pc == cc\n",
    "            f1 = 1\n",
    "        elif pc != cc:\n",
    "            char_level[\"over_corr\"] += 1\n",
    "            f2 = 1\n",
    "\n",
    "    if f1:\n",
    "        sent_level[\"true_corr\"] += all(pred_sentence == corr_sentence)\n",
    "        sent_level[\"total_err\"] += f1\n",
    "    sent_level[\"over_corr\"] += f2\n",
    "\n",
    "    return char_level, sent_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1008e61e-5560-4614-a9ae-78a4ed7391e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T08:01:06.913349Z",
     "iopub.status.busy": "2024-12-09T08:01:06.912348Z",
     "iopub.status.idle": "2024-12-09T08:01:06.920850Z",
     "shell.execute_reply": "2024-12-09T08:01:06.920850Z",
     "shell.execute_reply.started": "2024-12-09T08:01:06.913349Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, tokenizer, test_data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    matrices = [\"over_corr\", \"total_err\", \"true_corr\"]\n",
    "    test_char_level = {key: 0 for key in matrices}\n",
    "    test_sent_level = {key: 0 for key in matrices}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_data_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device).type(torch.float)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, src_mask=attention_mask)\n",
    "            logits = outputs.permute(0, 2, 1)\n",
    "\n",
    "            loss = F.cross_entropy(logits, labels, ignore_index=tokenizer.pad_token_id)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            t = torch.argmax(outputs, dim=-1)\n",
    "            nt = t * attention_mask\n",
    "            pred = tokenizer.batch_decode(nt, skip_special_tokens=True)\n",
    "\n",
    "            for i in range(len(t)):\n",
    "                char_level, sent_level = cal_err(input_ids[i], nt[i], labels[i])\n",
    "                test_char_level = {\n",
    "                    key: test_char_level[key] + v for key, v in char_level.items()\n",
    "                }\n",
    "                test_sent_level = {\n",
    "                    key: test_sent_level[key] + v for key, v in sent_level.items()\n",
    "                }\n",
    "        print(total_loss / len(test_data_loader), test_char_level, test_sent_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c6352d-f799-4aad-89ac-614b579f3190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T08:01:06.921854Z",
     "iopub.status.busy": "2024-12-09T08:01:06.921854Z",
     "iopub.status.idle": "2024-12-09T08:01:10.497215Z",
     "shell.execute_reply": "2024-12-09T08:01:10.497215Z",
     "shell.execute_reply.started": "2024-12-09T08:01:06.921854Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(checkpoint)\n",
    "encoder_model = BertModel.from_pretrained(checkpoint)\n",
    "\n",
    "# The Hyperparameters can be defined in config.py\n",
    "hidden_size = 1024\n",
    "num_layers = 2\n",
    "\n",
    "decoder_model = DecoderLSTM(\n",
    "    input_size=encoder_model.config.hidden_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    ")\n",
    "\n",
    "model = CombineBertModel(encoder_model=encoder_model, decoder_model=decoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c75e7320-399a-433c-9a54-fc87a9fe59b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T08:01:10.498221Z",
     "iopub.status.busy": "2024-12-09T08:01:10.498221Z",
     "iopub.status.idle": "2024-12-09T08:01:10.908741Z",
     "shell.execute_reply": "2024-12-09T08:01:10.908741Z",
     "shell.execute_reply.started": "2024-12-09T08:01:10.498221Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocessing sighan dataset: 2339it [00:00, 36154.20it/s]\n",
      "preprocessing sighan dataset: 100%|█████████████████████████████████████████████| 2339/2339 [00:00<00:00, 71696.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共2339句，共73264字，最长的句子有171字\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocessing sighan dataset: 3437it [00:00, 41217.27it/s]\n",
      "preprocessing sighan dataset: 100%|█████████████████████████████████████████████| 3437/3437 [00:00<00:00, 31171.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共3437句，共170330字，最长的句子有258字\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CSCDataset([SIGHAN_train_dir_err, SIGHAN_train_dir_corr], tokenizer)\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset, num_workers=0, shuffle=True, batch_size=16\n",
    ")\n",
    "\n",
    "test_dataset = CSCDataset([SIGHAN_train_dir_err14, SIGHAN_train_dir_corr14], tokenizer)\n",
    "test_data_loader = DataLoader(test_dataset, num_workers=0, shuffle=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afdade3d-8b1c-40f2-8d49-333072bb690c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T08:01:10.910747Z",
     "iopub.status.busy": "2024-12-09T08:01:10.909747Z",
     "iopub.status.idle": "2024-12-09T08:01:18.839633Z",
     "shell.execute_reply": "2024-12-09T08:01:18.839633Z",
     "shell.execute_reply.started": "2024-12-09T08:01:10.910747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombineBertModel(\n",
       "  (encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): DecoderLSTM(\n",
       "    (model): LSTM(768, 1024, num_layers=2, batch_first=True)\n",
       "  )\n",
       "  (linear): Linear(in_features=1024, out_features=21128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c89cef-d13b-4259-a2b4-357f06b78eb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T08:01:18.840638Z",
     "iopub.status.busy": "2024-12-09T08:01:18.840638Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1/50: 100%|████████████████████████████████████████████████████████| 147/147 [01:33<00:00,  1.57it/s, loss=5.635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "假 設 是 我 們 ， 一 旦 知 道 我 們 的 一 舉 一 動 都 有 人 觀 茶 ， 我 們 會 有 怎 麼 樣 的 感 覺 ？\n",
      "我 我 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的\n",
      "假 設 是 我 們 ， 一 旦 知 道 我 們 的 一 舉 一 動 都 有 人 觀 察 ， 我 們 會 有 怎 麼 樣 的 感 覺 ？\n",
      "({'over_corr': 32, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "我 下 次 回 家 的 時 候 一 定 會 清 他 ， 清 清 楚 楚 的 寫 下 來 一 些 蔡 的 做 法 ， 好 不 好 ？\n",
      "我 我 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的\n",
      "我 下 次 回 家 的 時 候 一 定 會 請 他 ， 清 清 楚 楚 的 寫 下 來 一 些 菜 的 做 法 ， 好 不 好 ？\n",
      "({'over_corr': 29, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "首 先 ， 我 要 說 明 他 為 什 麼 不 算 商 品 。 儘 管 卻 有 人 買 賣 牠 ， 我 想 那 種 行 為 是 不 對 的 。\n",
      "我 我 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的\n",
      "首 先 ， 我 要 說 明 牠 為 什 麼 不 算 商 品 。 儘 管 卻 有 人 買 賣 牠 ， 我 想 那 種 行 為 是 不 對 的 。\n",
      "({'over_corr': 35, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 1 Loss: 6.677673236042464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:2/50: 100%|████████████████████████████████████████████████████████| 147/147 [02:25<00:00,  1.01it/s, loss=5.612]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 也 受 到 了 經 濟 的 影 響 ： 我 們 是 要 上 班 但 是 薪 水 便 少 了 。\n",
      "我 我 我 我 ， ， ， ， ， 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的\n",
      "我 也 受 到 了 經 濟 的 影 響 ： 我 們 是 要 上 班 但 是 薪 水 變 少 了 。\n",
      "({'over_corr': 24, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "最 近 廠 長 裡 面 發 出 一 種 很 難 聞 的 味 道 ， 這 種 味 道 不 知 讓 我 們 村 裡 的 空 氣 汙 染 ， 而 還 讓 大 家 覺 得 害 怕 。\n",
      "我 我 我 我 ， ， ， ， ， ， 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的\n",
      "最 近 廠 長 裡 面 發 出 一 種 很 難 聞 的 味 道 ， 這 種 味 道 不 只 讓 我 們 村 裡 的 空 氣 汙 染 ， 而 還 讓 大 家 覺 得 害 怕 。\n",
      "({'over_corr': 42, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "我 那 樣 子 玩 大 概 兩 三 個 月 ， 每 一 個 禮 拜 根 不 一 樣 的 人 出 來 玩 ， 所 以 中 文 就 慢 慢 的 變 成 很 好 的 都 講 得 很 流 利 ， 還 有 因 為 常 常 在 電 腦 聊 天 打 子 都 打 得 很 快 ， 所 以 納 的 時 候 很 快 樂 。\n",
      "我 我 我 我 ， ， ， ， ， 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ， ， 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的\n",
      "我 那 樣 子 玩 大 概 兩 三 個 月 ， 每 一 個 禮 拜 跟 不 一 樣 的 人 出 來 玩 ， 所 以 中 文 就 慢 慢 地 變 成 很 好 的 都 講 得 很 流 利 ， 還 有 因 為 常 常 在 電 腦 聊 天 打 字 都 打 得 很 快 ， 所 以 那 個 時 候 很 快 樂 。\n",
      "({'over_corr': 69, 'total_err': 5, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 2 Loss: 5.63038935304499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:3/50: 100%|████████████████████████████████████████████████████████| 147/147 [02:39<00:00,  1.09s/it, loss=4.666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 很 想 跟 去 ， 可 是 沒 辦 法 有 考 試 ， 我 希 望 你 的 流 星 很 好 玩 ！\n",
      "我 一 一 一 一 的 的 的 我 一 一 的 一 一 ， 的 的 的 的 我 一 一 一 一 一 。\n",
      "我 很 想 跟 去 ， 可 是 沒 辦 法 有 考 試 ， 我 希 望 你 的 旅 行 很 好 玩 ！\n",
      "({'over_corr': 22, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "爸 爸 請 你 在 一 次 想 一 想 好 好 兒 的 辦 法 。\n",
      "我 一 一 的 我 一 一 一 一 一 一 一 了 ， 一 了 ，\n",
      "爸 爸 請 你 再 一 次 想 一 想 好 好 兒 的 辦 法 。\n",
      "({'over_corr': 14, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "營 為 他 們 在 書 店 三 個 鐘 頭 ， 所 以 我 弟 弟 此 他 朋 友 來 我 們 的 家 吃 飯 。\n",
      "我 我 我 我 我 一 一 一 一 一 一 ， 的 的 的 一 一 一 ， 一 一 的 ， 一 一 一 ，\n",
      "因 為 他 們 在 書 店 三 個 鐘 頭 ， 所 以 我 弟 弟 請 他 朋 友 來 我 們 的 家 吃 飯 。\n",
      "({'over_corr': 26, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 3 Loss: 5.334501415693841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:4/50: 100%|████████████████████████████████████████████████████████| 147/147 [02:43<00:00,  1.11s/it, loss=4.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你 去 一 前 ， 我 可 以 給 你 錢 。\n",
      "我 很 一 很 ， 我 不 以 一 我 好 。\n",
      "你 去 以 前 ， 我 可 以 給 你 錢 。\n",
      "({'over_corr': 7, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "有 的 表 現 不 好 的 孩 子 而 且 是 有 很 嚴 格 的 父 母 ， 他 們 回 家 時 一 定 是 被 捏 或 被 打 一 頓 ， 這 樣 他 們 可 台 可 憐 了 。\n",
      "我 我 很 一 不 好 的 一 一 一 一 ， 有 很 好 了 ， 很 很 ， 我 我 很 一 我 一 一 我 很 好 了 了 一 一 了 ， 一 一 ， 我 不 一 不 好 好 。\n",
      "有 的 表 現 不 好 的 孩 子 而 且 是 有 很 嚴 格 的 父 母 ， 他 們 回 家 時 一 定 是 被 捏 或 被 打 一 頓 ， 這 樣 他 們 可 太 可 憐 了 。\n",
      "({'over_corr': 35, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "經 過 這 件 事 不 是 你 也 長 大 了 不 少 ， 對 碼 ？\n",
      "一 一 在 很 一 不 我 我 一 好 很 了 不 好 ， 好 了 。\n",
      "經 過 這 件 事 不 是 你 也 長 大 了 不 少 ， 對 嗎 ？\n",
      "({'over_corr': 13, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 4 Loss: 4.875095458257766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:5/50: 100%|████████████████████████████████████████████████████████| 147/147 [02:47<00:00,  1.14s/it, loss=4.070]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "因 為 表 哥 說 現 在 他 遇 到 的 問 題 是 一 個 大 考 驗 ， 所 以 他 應 該 必 須 很 正 面 地 面 對 這 個 大 考 驗 以 及 不 斷 的 努 力 去 解 決 它 。\n",
      "因 為 了 了 ， 在 在 他 很 到 的 一 好 是 一 個 大 了 了 ， 所 以 他 一 很 了 來 很 了 人 ， 人 人 這 個 大 了 了 以 了 不 了 的 了 。 人 了 了 在 。\n",
      "因 為 表 哥 說 現 在 他 遇 到 的 問 題 是 一 個 大 考 驗 ， 所 以 他 應 該 必 須 很 正 面 地 面 對 這 個 大 考 驗 以 及 不 斷 地 努 力 去 解 決 它 。\n",
      "({'over_corr': 28, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "因 為 他 走 天 才 到 台 北 來 ， 所 以 他 不 知 道 怎 去 學 校 。\n",
      "因 為 他 很 天 很 到 很 了 來 ， 所 以 他 不 很 一 了 了 去 了 了 。\n",
      "因 為 他 昨 天 才 到 台 北 來 ， 所 以 他 不 知 道 怎 麼 去 學 校 。\n",
      "({'over_corr': 8, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "媒 體 上 整 天 在 提 出 這 種 觀 點 ， 批 評 主 婦 的 該 念 快 是 一 種 時 髦 ， 而 很 少 會 聽 到 好 處 根 樂 趣 。\n",
      "很 一 上 很 天 在 了 了 這 很 了 了 ， 了 了 了 了 的 一 了 了 是 一 很 ， 了 ， 一 很 很 會 很 到 好 了 來 了 了 。\n",
      "媒 體 上 整 天 在 提 出 這 種 觀 點 ， 批 評 主 婦 的 概 念 快 是 一 種 時 髦 ， 而 很 少 會 聽 到 好 處 跟 樂 趣 。\n",
      "({'over_corr': 23, 'total_err': 2, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 5 Loss: 4.286900371110359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:6/50: 100%|████████████████████████████████████████████████████████| 147/147 [02:47<00:00,  1.14s/it, loss=3.267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "因 為 那 個 時 候 是 第 一 次 上 課 ， 所 以 他 看 起 來 跟 老 師 不 開 方 。\n",
      "因 為 這 個 時 候 是 這 一 不 上 很 ， 所 以 他 看 了 來 跟 老 師 不 人 方 。\n",
      "因 為 那 個 時 候 是 第 一 次 上 課 ， 所 以 他 看 起 來 跟 老 師 不 開 放 。\n",
      "({'over_corr': 6, 'total_err': 1, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "在 花 蓮 縣 去 年 一 位 特 殊 的 高 中 生 因 未 收 到 老 師 的 色 情 暴 力 懷 孕 ， 那 件 事 造 成 連 學 長 格 致 。\n",
      "在 學 了 上 去 年 一 個 了 了 的 學 人 生 因 很 影 到 老 師 的 了 情 了 了 了 了 ， 這 很 事 影 好 上 學 大 了 了 。\n",
      "在 花 蓮 縣 去 年 一 位 特 殊 的 高 中 生 因 為 受 到 老 師 的 色 情 暴 力 懷 孕 ， 那 件 事 造 成 連 學 長 革 職 。\n",
      "({'over_corr': 19, 'total_err': 4, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "可 是 ， 能 有 多 少 人 知 道 現 在 北 極 冰 榮 化 的 很 嚴 重 ， 我 們 的 地 球 越 來 越 熱 ， 天 災 不 段 的 發 生 等 ， 原 因 何 在 呢 ？\n",
      "可 是 ， 能 有 多 人 人 很 道 現 在 自 了 了 了 了 的 很 了 很 ， 我 們 的 地 家 自 來 自 了 ， 天 影 不 自 的 生 生 了 ， 學 因 了 在 了 ？\n",
      "可 是 ， 能 有 多 少 人 知 道 現 在 北 極 冰 融 化 的 很 嚴 重 ， 我 們 的 地 球 越 來 越 熱 ， 天 災 不 斷 地 發 生 等 ， 原 因 何 在 呢 ？\n",
      "({'over_corr': 18, 'total_err': 3, 'true_corr': tensor(0, device='cuda:0')}, {'over_corr': 1, 'total_err': 1, 'true_corr': 0})\n",
      "Epoch 6 Loss: 3.4215415643185985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:7/50:   3%|█▉                                                        | 5/147 [00:05<02:37,  1.11s/it, loss=2.917]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(\n",
    "        enumerate(train_data_loader),\n",
    "        desc=f\"Epoch:{epoch+1}/{epochs}\",\n",
    "        total=len(train_data_loader),\n",
    "    )\n",
    "\n",
    "    for i, batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device).type(torch.float)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, src_mask=attention_mask)\n",
    "        logits = outputs.permute(0, 2, 1)  # (batch_size, vocab_size, seq_len)\n",
    "\n",
    "        # 反向传播在这，故labels不需要传入模型\n",
    "        loss = F.cross_entropy(logits, labels, ignore_index=tokenizer.pad_token_id)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        progress_bar.set_postfix({\"loss\": \"{:.3f}\".format(loss.item())})\n",
    "\n",
    "    t = torch.argmax(outputs, dim=-1)\n",
    "    nt = t * attention_mask\n",
    "    pred = tokenizer.batch_decode(nt, skip_special_tokens=True)\n",
    "    # print(pred)\n",
    "    # print(f\"origin{tokenizer.batch_decode(labels, skip_special_tokens=True)}\")\n",
    "\n",
    "    for i, v in enumerate(nt):\n",
    "        r, l = input_ids[i], labels[i]\n",
    "        print(tokenizer.decode(r, skip_special_tokens=True))\n",
    "        print(tokenizer.decode(v, skip_special_tokens=True))\n",
    "        print(tokenizer.decode(l, skip_special_tokens=True))\n",
    "        print(cal_err(r, v, l))\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss / len(train_data_loader)}\")\n",
    "    # test(model, tokenizer, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7ea434-79e9-4310-b572-8c5367b84212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc_env",
   "language": "python",
   "name": "csc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
